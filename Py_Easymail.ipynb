{"cells":[{"cell_type":"markdown","metadata":{"id":"-ZKemb11VlJD"},"source":["# Structuration DataSet (A ne plus relancer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8u5xskFVyMI","executionInfo":{"status":"ok","timestamp":1655902578547,"user_tz":-120,"elapsed":28046,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bebd3da5-9721-485f-c5b5-6798b6917ffa"},"outputs":[{"output_type":"stream","name":"stdout","text":["(405968, 6)\n","(227032, 5)\n"]}],"source":["# Mount GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# On concaténe les 6 fichiers\n","import pandas as pd\n","df_0 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_0.csv\")\n","df_1 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_1.csv\")\n","df_2 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_2.csv\")\n","df_3 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_3.csv\")\n","df_4 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_4.csv\")\n","df_5 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_5.csv\")\n","# df = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron.csv\", nrows=1500)\n","frames = [df_0,df_1,df_2,df_3,df_4,df_5]\n","df = pd.concat(frames)\n","# la selection ci-dessous a permis de détecter 3 doublons (toutes colonnes identiques)\n","# df = df.loc[(df['subject'] == \"Sagewood Town Homes\")]\n","print(df.shape)\n","# df = df_emails.loc[(df['subject'] == \"Sagewood Town Homes\")]\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","# suppression des doublons (sur toutes les colonnes sauf index)\n","df.drop_duplicates(subset=['date','sender', 'recipient1', 'subject','text'],keep = 'first', inplace=True)\n","# on renomme les colonnes\n","df = df.rename(columns={'sender': 'from', 'recipient1': 'to','subject': 'header', 'text': 'body'})\n","# et export en csv du résultat.\n","file_name = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique.csv\"\n","df.to_csv(file_name, encoding='utf-8', index=False)\n","print(df.shape)\n","# Taille du fichier divisée par 2 environ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1655902578548,"user":{"displayName":"Nico T","userId":"09615745923254077330"},"user_tz":-120},"id":"YP8TOi7VWtOs","outputId":"a12d4ace-5499-432f-ab08-caf9ae7dc2e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 227032 entries, 0 to 11736\n","Data columns (total 5 columns):\n"," #   Column  Non-Null Count   Dtype \n","---  ------  --------------   ----- \n"," 0   date    227032 non-null  object\n"," 1   from    227032 non-null  object\n"," 2   to      227032 non-null  object\n"," 3   header  218946 non-null  object\n"," 4   body    227032 non-null  object\n","dtypes: object(5)\n","memory usage: 10.4+ MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","source":["# Data Preprocessing - cleaning"],"metadata":{"id":"AQ7Tk9bJn1Gw"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"_giUgOlhsiSj","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1655910476481,"user_tz":-120,"elapsed":4790,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"d5be8993-f0d2-41f7-e8e4-c1feca3fab4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["                        date                     from  \\\n","0  2001-05-14 16:39:00-07:00  phillip.allen@enron.com   \n","1  2001-05-04 13:51:00-07:00  phillip.allen@enron.com   \n","2  2000-10-18 03:00:00-07:00  phillip.allen@enron.com   \n","3  2000-10-23 06:13:00-07:00  phillip.allen@enron.com   \n","4  2000-08-31 05:07:00-07:00  phillip.allen@enron.com   \n","\n","                        to     header  \\\n","0     tim.belden@enron.com        NaN   \n","1  john.lavorato@enron.com        Re:   \n","2   leah.arsdall@enron.com   Re: test   \n","3    randall.gay@enron.com        NaN   \n","4     greg.piper@enron.com  Re: Hello   \n","\n","                                                body  \n","0              ['', 'Here is our forecast', '', ' ']  \n","1  ['', 'Traveling to have a business meeting tak...  \n","2             ['', 'test successful.  way to go!!!']  \n","3  ['', 'Randy,', '', ' Can you send me a schedul...  \n","4        ['', \"Let's shoot for Tuesday at 11:45.  \"]  "],"text/html":["\n","  <div id=\"df-a8a30ce0-63c0-4086-9e96-3d4787916c98\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>from</th>\n","      <th>to</th>\n","      <th>header</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2001-05-14 16:39:00-07:00</td>\n","      <td>phillip.allen@enron.com</td>\n","      <td>tim.belden@enron.com</td>\n","      <td>NaN</td>\n","      <td>['', 'Here is our forecast', '', ' ']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2001-05-04 13:51:00-07:00</td>\n","      <td>phillip.allen@enron.com</td>\n","      <td>john.lavorato@enron.com</td>\n","      <td>Re:</td>\n","      <td>['', 'Traveling to have a business meeting tak...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2000-10-18 03:00:00-07:00</td>\n","      <td>phillip.allen@enron.com</td>\n","      <td>leah.arsdall@enron.com</td>\n","      <td>Re: test</td>\n","      <td>['', 'test successful.  way to go!!!']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2000-10-23 06:13:00-07:00</td>\n","      <td>phillip.allen@enron.com</td>\n","      <td>randall.gay@enron.com</td>\n","      <td>NaN</td>\n","      <td>['', 'Randy,', '', ' Can you send me a schedul...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2000-08-31 05:07:00-07:00</td>\n","      <td>phillip.allen@enron.com</td>\n","      <td>greg.piper@enron.com</td>\n","      <td>Re: Hello</td>\n","      <td>['', \"Let's shoot for Tuesday at 11:45.  \"]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a30ce0-63c0-4086-9e96-3d4787916c98')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a8a30ce0-63c0-4086-9e96-3d4787916c98 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a8a30ce0-63c0-4086-9e96-3d4787916c98');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1}],"source":["# Mount GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import pandas as pd\n","# Pour limiter les temps de calcul on travaille uniquement sur les 'nrows' premiers mails\n","df = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique.csv\", nrows=1000)\n","df.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7uLPAsx-tPfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910476482,"user_tz":-120,"elapsed":20,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"b33b42eb-ad55-4c77-d182-e0c8c3c7bd1b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["149"]},"metadata":{},"execution_count":2}],"source":["# nbre d'expéditeurs distincts\n","len(df['from'].unique())"]},{"cell_type":"code","source":["# nbre de destinataires distincts\n","len(df['to'].unique())"],"metadata":{"id":"9itN2Crz6yKN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910476482,"user_tz":-120,"elapsed":16,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"90892b8b-1f6f-4a9e-df38-23d0392d6462"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["231"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"geS2lCMeIpwf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910476483,"user_tz":-120,"elapsed":15,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"21c7bcf8-1ce7-4e8c-fd1e-3b606b74f708"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 9 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   date        1000 non-null   object\n"," 1   from        1000 non-null   object\n"," 2   to          1000 non-null   object\n"," 3   header      784 non-null    object\n"," 4   body        1000 non-null   object\n"," 5   NER_header  1000 non-null   object\n"," 6   NER_body    1000 non-null   object\n"," 7   body_dict   1000 non-null   object\n"," 8   summary     1000 non-null   object\n","dtypes: object(9)\n","memory usage: 70.4+ KB\n"]}],"source":["import numpy as np\n","df = df.replace('NaN', np.NaN)\n","# df_emails = df[df['header'].notna()]\n","df_emails = df\n","df_emails['NER_header'] = ''\n","df_emails['NER_body'] = ''\n","df_emails['body_dict'] = ''\n","df_emails['summary'] = ''\n","df_emails.info()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QPpuAqcYhyLB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910476484,"user_tz":-120,"elapsed":14,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"74a02ebb-45e7-4afe-8e2b-59e4f2bc3b35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['date', 'from', 'to', 'header', 'body', 'NER_header', 'NER_body',\n","       'body_dict', 'summary'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}],"source":["df_emails.columns"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yh4-upAdXbSS","executionInfo":{"status":"ok","timestamp":1655910476485,"user_tz":-120,"elapsed":12,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"outputs":[],"source":["#\n","# A ce stade le fichier a la structure nécessaire à Melusine pour le nettoyage\n","#"]},{"cell_type":"code","source":["# !pip install -U spacy\n","#!python -m spacy download en_core_web_sm\n","\n","\n"],"metadata":{"id":"FEbHex0arHC_","executionInfo":{"status":"ok","timestamp":1655910476485,"user_tz":-120,"elapsed":11,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_sm')\n","spacy_stopwords = nlp.Defaults.stop_words\n","stopwords = spacy_stopwords\n","print(spacy_stopwords)"],"metadata":{"id":"sHTuVMN4iZaQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910480832,"user_tz":-120,"elapsed":4357,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"1cbab19c-0afb-4e8e-d35d-972148a0c6f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{\"'s\", 'a', 'anywhere', 'been', 'across', 'former', 'whenever', 'over', 'off', 'on', 'whence', 'made', 'to', 'very', 'can', 'somehow', 'everywhere', 'third', 'full', 'here', 'once', 'call', 'might', 'regarding', '‘ve', 'against', 'several', 'two', 'us', 'your', 'many', 'no', 'sixty', 'still', 'indeed', 'among', 'nevertheless', 'such', 'seeming', 'whose', 'see', 'nobody', 'every', 'would', \"'ve\", 'almost', 'because', 'least', 'before', 'formerly', 'doing', 'afterwards', 'further', 'hereafter', 'up', 'mostly', 'those', 'latter', 'whole', \"n't\", '’m', 'with', 'than', 'most', 'anything', 'him', 'through', 'as', 'ours', 'elsewhere', 'these', 'something', 'there', 'twenty', 'next', 'had', 'though', 'fifteen', 'neither', 'therefore', 'herein', 'although', 'hence', 'should', 'my', 'unless', 'done', 'along', 'after', 'both', 'otherwise', 'besides', 'onto', 'i', 'ever', 'yours', 'more', 'become', 'less', 'twelve', 'five', 'per', 'some', \"'d\", 'it', 'seem', 'below', 'by', \"'re\", 'our', 'they', 'give', 'beyond', 'toward', 'nowhere', 'few', 'towards', 'various', 'also', 'throughout', 'mine', 'seemed', '‘d', 'other', 'namely', 'anyone', 'take', 'meanwhile', 'thence', 'how', 'together', 'bottom', 'herself', 'whoever', 'never', 'go', 'behind', 'seems', 'in', 'three', 'between', 'hundred', 'sometimes', 'thus', 'above', 'via', 'where', 'without', \"'m\", 'noone', 'its', 'upon', '‘ll', 'everything', 'am', 'yourself', 'even', 'whom', 'nine', 'while', 'now', 'being', 'of', '‘s', 'whereas', 'really', 'which', 'already', 'sometime', 're', 'just', 'any', 'anyway', 'top', 'thereupon', 'from', 'ourselves', 'own', 'amount', 'else', 'around', 'again', 'nor', 'therein', 'but', 'he', 'whatever', 'itself', 'she', 'however', 'an', 'yet', 'always', 'have', '’re', 'n’t', 'wherever', 'n‘t', 'one', 'does', 'same', 'out', 'everyone', 'each', 'moreover', 'forty', 'beside', '’ll', 'their', 'quite', 'six', 'only', 'me', 'ca', 'name', 'front', 'so', 'show', 'please', 'are', '’s', 'under', 'enough', 'eleven', 'others', 'this', 'hereupon', 'into', 'keep', 'when', 'may', 'why', '‘re', 'alone', 'thru', 'part', 'whether', 'hereby', 'you', 'becoming', 'down', 'her', 'another', 'put', 'fifty', 'or', 'serious', 'latterly', 'perhaps', 'move', 'we', \"'ll\", 'the', 'used', '’d', 'often', 'themselves', 'be', 'whither', 'then', 'cannot', 'much', 'during', 'somewhere', 'for', '‘m', 'and', 'do', 'wherein', 'none', 'became', 'that', 'all', 'say', 'hers', 'last', 'four', 'since', 'himself', 'myself', 'first', 'nothing', 'at', 'not', 'is', 'them', 'yourselves', 'amongst', 'will', 'eight', 'using', 'whereafter', 'who', 'make', 'was', 'until', 'has', 'ten', 'could', 'empty', 'either', '’ve', 'did', 'someone', 'rather', 'whereupon', 'within', 'beforehand', 'anyhow', 'about', 'except', 'becomes', 'his', 'if', 'must', 'due', 'well', 'too', 'were', 'whereby', 'side', 'back', 'get', 'thereby', 'what', 'thereafter'}\n"]}]},{"cell_type":"code","source":["import nltk\n","# nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","import re\n","\n","def untokenize (tokens):\n","# Suppression des caractres spéciaux ou inutiles \\\"',]\n","  r = re.compile(r\"[\\\\\\''\\\",]\")\n","  texte=r.sub('', tokens)\n","  texte = sent_tokenize(texte)\n","#  print(\"Après :\\n\",type(texte),\" \",texte)\n","  return texte"],"metadata":{"id":"J3AM6gXAjKn2","executionInfo":{"status":"ok","timestamp":1655910480833,"user_tz":-120,"elapsed":9,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def remove_stop_words(text,stopwords):\n","  lst=[]\n","  for token in str(text).split():\n","    if token.lower() not in stopwords:    #checking whether the word is not \n","      lst.append(token)                    #present in the stopword list.      \n","  # Join items in the list\n","#  print(\"Original text  : \",text)\n","  result = ' '.join(lst)\n","#  print(\"Text after removing stopwords  :   \",result)\n","  return result"],"metadata":{"id":"S_I3qqRIt79M","executionInfo":{"status":"ok","timestamp":1655910480834,"user_tz":-120,"elapsed":9,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Transforme Text en Dictionnaire - Key = indice de phrase - Value = Mots de la phrase\n","import re\n","from nltk.tokenize import sent_tokenize,word_tokenize\n","\n","def dictionarize(article):\n","    dico={}\n","    phrases=sent_tokenize(article)\n","    phr2=[]\n","    for i, phr in enumerate(phrases):\n","        import re\n","        phr=re.sub(pattern =\"[^a-zA-Z]\", repl = ' ', string = phr)\n","        phr2.append(phr)\n","    \n","        phr=word_tokenize(phr)\n","        phr_lower=[w.lower() for w in phr]\n","        if len(phr_lower)>4:      \n","            dico[i]=phr_lower    \n","    return dico\n","\n"],"metadata":{"id":"v7Enu2jNVjHU","executionInfo":{"status":"ok","timestamp":1655910480834,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df_emails.shape[0]"],"metadata":{"id":"YdwAE_vc_o5o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910480834,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"c1070c35-6a0e-45fb-aeac-806c0a4be819"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# test unitaire de la fonction dictionarize sur une ligne\n","#\n","# artikle = dictionarize(df_emails['body'][32])\n","# for cle, valeur in artikle.items():\n","#        print(\"clé\", cle, \"vaut\", valeur)"],"metadata":{"id":"uNzCe6vWHyC2","executionInfo":{"status":"ok","timestamp":1655910480835,"user_tz":-120,"elapsed":7,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","\n","def TF(token, artikle):\n","    \"\"\"\n","    Calcule le score TF d'un mot dans un artikle\n","    \n","    token : Mot dont le score TF doit être calculé.\n","    \n","    artikle : Dictionnaire généré à partir d'un texte.\n","    \"\"\"\n","    f = 0\n","    for key in artikle:\n","        for work in artikle[key]:\n","            if work == token:\n","                f += 1 \n","    return np.log(f+1)\n","\n","def IDF(token, corpus):\n","    \"\"\"\n","    Calcule le score IDF d'un mot dans un corpus d'artikles.\n","    \n","    token : Mot dont le score IDF doit être calculé.\n","    \n","    corpus : Liste d'artikles.\n","    \"\"\"\n","    N = len(corpus)\n","    d=0\n","    present = False\n","    \n","    for artikle in corpus:\n","        for key in artikle:\n","            if token in artikle[key]:\n","                present = True\n","        d += int(present)\n","        present = False\n","                \n","    return np.log(N/(d+1) +1)\n","\n","def TFIDF(token, artikle, corpus):\n","    \"\"\"\n","    Calcule le score TF-IDF d'un mot dans un texte.\n","    \n","    token : mot dont le score doit être calculé.\n","    \n","    artikle : artikle qui servira à calculer le score du mot dans cet artikle.\n","    \n","    corpus : Liste d'artikles formant le corpus.\n","    \"\"\"\n","    return TF(token, artikle)*IDF(token, corpus)\n","\n","def score_sentence(corpus, artikle, sentence):\n","    \"\"\"\n","    Calcule le score d'une phrase.\n","    \n","    corpus : Liste d'artikles.\n","    \n","    artikle : Dictionnaire de phrases.\n","    \n","    sentence : Phrase sous forme de liste de mots.\n","    \"\"\"\n","    score_sentence = []\n","    for word in sentence :\n","        score_word = TFIDF(word, artikle, corpus)\n","        score_sentence.append(score_word)\n","    return np.mean(score_sentence)\n","\n","def best_sentences(scores_artikle, nb_sentences):\n","    \"\"\"\n","    Retourne les indices des phrases les plus importantes en fonction des scores obtenus.\n","    \n","    scores_artikle : Liste des scores de chaque phrase dans un texte.\n","    \n","    nb_sentences : Nombre de phrases à sélectionner.\n","    \"\"\"\n","    \n","    return sorted(np.argsort(scores_artikle)[-nb_sentences:])\n","\n","def summarize(i, n_sentences, df):\n","    \"\"\"\n","    Synthèse extractive d'un article par la méthode TF-IDF.\n","    \n","    i : indice de l'article dans le corpus.\n","    \n","    n_sentences : nombre de phrases à conserver.\n","    \n","    df : DataFrame contenant les artikles dans une colonne 'Artikle'.    \n","    \"\"\"\n","    corpus = df['body_dict']\n","    artikle = corpus[i]\n","    texte=df['body'][i]\n","    \n","    \n","    # Calcul du score de chaque phrase de l'artikle\n","    scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle.values()]\n"," \n","    \n","    # Extraction des indices des phrases ayant les meilleurs scores\n","    result = best_sentences(scores_artikle, n_sentences)\n","#    print('best sentences :',result)\n","    \n","    # Séparation de phrases l'article original \n","    tokenized_article = sent_tokenize(texte)\n","    \n","    # Extraction des phrases les plus importantes\n","    summary = [tokenized_article[i] for i in result]\n","#    print(summary)\n","    return summary"],"metadata":{"id":"E_flKIgS5ra2","executionInfo":{"status":"ok","timestamp":1655910481364,"user_tz":-120,"elapsed":536,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Nettoyage : Détokenisation et retokenisation en sentences\n","deb = 0\n","fin = df_emails.shape[0]\n","\n","for id in range(deb,fin):\n","  text = df_emails['body'].iloc[id]\n","  text = untokenize(text)\n","  text = dictionarize(str(text))\n","  df_emails['body_dict'][id] = text\n","  # résumé dans le champ 'summarize' en 3 lignes au plus.\n","  df_emails['summary'][id] = summarize(id, 3, df_emails)\n"],"metadata":{"id":"dQ8G9SzEFtFL","executionInfo":{"status":"ok","timestamp":1655910986564,"user_tz":-120,"elapsed":505202,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["df_emails['body'][32]"],"metadata":{"id":"h8ha9jRhXy_C","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1655910986565,"user_tz":-120,"elapsed":24,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"2a9591dc-76d4-48ea-e888-3bd532de250f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[\\'\\', \\'---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000 \\', \\'11:57 AM ---------------------------\\', \\'\\', \\'\\', \\'\"BS Stone\" <bs_stone@yahoo.com> on 09/26/2000 04:47:40 AM\\', \\'To: \"jeff\" <jeff@freeyellow.com>\\', \\'cc: \"Phillip K Allen\" <Phillip.K.Allen@enron.com> \\', \\'Subject: closing\\', \\'\\', \\'\\', \\'\\', \\'Jeff, \\', \\'?\\', \"Is the closing today?? After reviewing the  agreement?I find it isn\\'t binding \", \"as far as I can determine.? It is  too vague and it doesn\\'t sound like \", \\'anything an attorney or title company  would?draft for a real estate \\', \\'closing--but, of course, I could be  wrong.? \\', \\'?\\', \\'If this?closing is going to take place without  this agreement then there is \\', \"no point in me  following up on this?document\\'s validity.? \", \\'?\\', \"I will just need to go back to my closing documents  and see what\\'s there and \", \\'find out where I am with that and deal with this as  best I can.\\', \\'?\\', \\'I guess I was expecting something that would be an  exhibit to a recordable \\', \\'document or something a little more exact, or  rather?sort of a contract.? \\', \"This isn\\'t either.? I tried to get a  real estate atty on the phone last \", \\'night but he was out of pocket.? I  talked to a crim. atty friend and he said \\', \"this is out of his area but doesn\\'t  sound binding to him.? \", \\'?\\', \"I will go back to mine and Phillip Allen\\'s  transaction?and take a look at \", \\'that but as vague and general as this is I  doubt that my signature? is even \\', \\'needed to complete this transaction.?  I am in after 12 noon if there is any \\', \\'need to contact me regarding the  closing.\\', \\'?\\', \\'I really do not want to hold up anything or  generate more work for myself \\', \"and I don\\'t want to insult or annoy anyone but  this paper really doesn\\'t \", \\'seem to be something required for a closing.? In  the event you do need my \\', \\'signature on something like this I would rather have  time to have it \\', \\'reviewed before I accept it.\\', \\'?\\', \\'Brenda\\', \\'?\\', \\'?\\', \\'\\']'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df_emails['summary'][32]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gs0vAM2z8M1V","executionInfo":{"status":"ok","timestamp":1655910986565,"user_tz":-120,"elapsed":21,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"f9c8d4e5-1815-46a3-ce19-ee4a42b08685"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"', '?\",\n"," '\\', \"I will just need to go back to my closing documents  and see what\\'s there and \", \\'find out where I am with that and deal with this as  best I can.',\n"," \"', 'I guess I was expecting something that would be an  exhibit to a recordable ', 'document or something a little more exact, or  rather?sort of a contract.?\"]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[""],"metadata":{"id":"4fpiwZTG8NCe","executionInfo":{"status":"ok","timestamp":1655910986566,"user_tz":-120,"elapsed":19,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# texte fonction de résumé sur la ligne 'id'\n","#id = 12\n","#print(df_emails['body'][id])\n","#for cle, valeur in df_emails['body_dict'][id].items():\n","#        print(\"Ligne \", cle, \"vaut\", valeur)\n","#\n","#\n","#print('summary :\\n\\n',summarize(id, 3, df_emails))\n","#\n","# df_emails['summary'].iloc[id] = summarize(id, 5, df_emails)\n","# print(df_emails['summary'][id])"],"metadata":{"id":"Jf30ZxO65sSJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655910991908,"user_tz":-120,"elapsed":5360,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"3ac91d3f-1fa6-42d2-d12c-5703f982fb76"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Ligne  0 vaut ['forwarded', 'by', 'phillip', 'k', 'allen', 'hou', 'ect', 'on', 'pm', 'richard', 'burchfield', 'am', 'to', 'phillip', 'k', 'allen', 'hou', 'ect', 'ect', 'cc', 'beth', 'perlman', 'hou', 'ect', 'ect', 'subject', 'consolidated', 'positions', 'issues', 'to', 'do', 'list', 'phillip', 'below', 'is', 'the', 'issues', 'to', 'do', 'list', 'as', 'we', 'go', 'forward', 'with', 'documenting', 'the', 'requirements', 'for', 'consolidated', 'physical', 'financial', 'positions', 'and', 'transport', 'trade', 'capture']\n","Ligne  1 vaut ['what', 'we', 'need', 'to', 'focus', 'on', 'is', 'the', 'first', 'bullet', 'in', 'allans', 'list', 'the', 'need', 'for', 'a', 'single', 'set', 'of', 'requirements']\n","Ligne  2 vaut ['although', 'the', 'meeting', 'with', 'keith', 'on', 'wednesday', 'was', 'informative', 'the', 'solution', 'of', 'creating', 'a', 'infinitely', 'dynamic', 'consolidated', 'position', 'screen', 'will', 'be', 'extremely', 'difficult', 'and', 'time', 'consuming']\n","Ligne  3 vaut ['throughout', 'the', 'meeting', 'on', 'wednesday', 'keith', 'alluded', 'to', 'the', 'inability', 'to', 'get', 'consensus', 'amongst', 'the', 'traders', 'on', 'the', 'presentation', 'of', 'the', 'consolidated', 'position', 'so', 'the', 'solution', 'was', 'to', 'make', 'it', 'so', 'that', 'a', 'trader', 'can', 'arrange', 'the', 'position', 'screen', 'to', 'their', 'liking', 'much', 'like', 'excel']\n","Ligne  4 vaut ['what', 'needs', 'to', 'happen', 'on', 'monday', 'from', 'is', 'a', 'effort', 'to', 'design', 'a', 'desired', 'layout', 'for', 'the', 'consolidated', 'position', 'screen', 'this', 'is', 'critical']\n","Ligne  5 vaut ['this', 'does', 'not', 'exclude', 'building', 'a', 'capability', 'to', 'create', 'a', 'more', 'flexible', 'position', 'presentation', 'for', 'the', 'future', 'but', 'in', 'order', 'to', 'create', 'a', 'plan', 'that', 'can', 'be', 'measured', 'we', 'need', 'firm', 'requirements']\n","Ligne  6 vaut ['also', 'to', 'reiterate', 'that', 'the', 'goals', 'of', 'this', 'project', 'is', 'a', 'project', 'plan', 'on', 'consolidate', 'physical', 'financial', 'positions', 'and', 'transport', 'trade', 'capture']\n","Ligne  7 vaut ['the', 'other', 'issues', 'that', 'have', 'been', 'raised', 'will', 'be', 'capture', 'as', 'projects', 'on', 'to', 'themselves', 'and', 'will', 'need', 'to', 'be', 'prioritised', 'as', 'efforts', 'outside', 'of', 'this', 'project']\n","Ligne  8 vaut ['i', 'have', 'been', 'involved', 'in', 'most', 'of', 'the', 'meetings', 'and', 'the', 'discussions', 'have', 'been', 'good']\n","Ligne  9 vaut ['i', 'believe', 'there', 'has', 'been', 'good', 'communication', 'between', 'the', 'teams', 'but', 'now', 'we', 'need', 'to', 'have', 'focus', 'on', 'the', 'objectives', 'we', 'set', 'out', 'to', 'solve']\n","Ligne  10 vaut ['richard', 'forwarded', 'by', 'richard', 'burchfield', 'hou', 'ect', 'on', 'am', 'allan', 'severude', 'pm', 'to', 'richard', 'burchfield', 'hou', 'ect', 'ect', 'cc', 'peggy', 'alix', 'hou', 'ect', 'ect', 'russ', 'severson', 'hou', 'ect', 'ect', 'scott', 'mills', 'hou', 'ect', 'ect', 'kenny', 'ha', 'hou', 'ect', 'ect', 'subject', 'consolidated', 'positions', 'issues', 'to', 'do', 'list', 'from', 'our', 'initial', 'set', 'of', 'meetings', 'with', 'the', 'traders', 'regarding', 'consolidated', 'positions', 'i', 'think', 'we', 'still', 'have', 'the', 'following', 'issues', 'we', 'dont', 'have', 'a', 'single', 'point', 'of', 'contact', 'from', 'the', 'trading', 'group']\n","Ligne  11 vaut ['weve', 'had', 'three', 'meetings', 'which', 'brought', 'out', 'very', 'different', 'issues', 'from', 'different', 'traders']\n","Ligne  12 vaut ['we', 'really', 'need', 'a', 'single', 'point', 'of', 'contact', 'to', 'help', 'drive', 'the', 'trader', 'requirements', 'and', 'help', 'come', 'to', 'a', 'consensus', 'regarding', 'the', 'requirements']\n","Ligne  13 vaut ['were', 'getting', 'hit', 'with', 'a', 'lot', 'of', 'different', 'requests', 'many', 'of', 'which', 'appear', 'to', 'be', 'outside', 'the', 'scope', 'of', 'position', 'consolidation']\n","Ligne  14 vaut ['things', 'left', 'to', 'do', 'i', 'think', 'it', 'may', 'be', 'useful', 'to', 'try', 'to', 'formulate', 'a', 'high', 'level', 'project', 'goal', 'to', 'make', 'it', 'as', 'clear', 'as', 'possible', 'what', 'were', 'trying', 'to', 'accomplish', 'with', 'this', 'project']\n","Ligne  15 vaut ['itll', 'help', 'determine', 'which', 'requests', 'fall', 'under', 'the', 'project', 'scope']\n","Ligne  16 vaut ['go', 'through', 'the', 'list', 'of', 'requests', 'to', 'determine', 'which', 'are', 'in', 'scope', 'for', 'this', 'project', 'and', 'which', 'fall', 'out', 'of', 'scope']\n","Ligne  17 vaut ['for', 'those', 'in', 'scope', 'work', 'to', 'define', 'relative', 'importance', 'priority', 'of', 'each', 'and', 'work', 'with', 'traders', 'to', 'define', 'the', 'exact', 'requirements', 'of', 'each']\n","Ligne  18 vaut ['define', 'the', 'desired', 'lay', 'out', 'of', 'the', 'position', 'manager', 'screen', 'main', 'view', 'and', 'all', 'drill', 'downs']\n","Ligne  19 vaut ['use', 'the', 'above', 'to', 'formulate', 'a', 'project', 'plan']\n","Ligne  20 vaut ['things', 'requested', 'thus', 'far', 'no', 'particular', 'order', 'inclusion', 'of', 'sitara', 'physical', 'deals', 'into', 'the', 'tds', 'position', 'manager', 'and', 'deal', 'ticker']\n","Ligne  21 vaut ['customized', 'rows', 'and', 'columns', 'in', 'the', 'position', 'manager', 'ad', 'hoc', 'rows', 'columns', 'that', 'add', 'up', 'existing', 'position', 'manager', 'rows', 'columns']\n","Ligne  22 vaut ['new', 'drill', 'down', 'in', 'the', 'position', 'manager', 'to', 'break', 'out', 'positions', 'by', 'physical', 'transport', 'swaps', 'options', 'addition', 'of', 'a', 'curve', 'tab', 'to', 'the', 'position', 'manager', 'to', 'show', 'the', 'real', 'time', 'values', 'of', 'all', 'curves', 'on', 'which', 'the', 'desk', 'has', 'a', 'position']\n","Ligne  23 vaut ['ability', 'to', 'split', 'the', 'current', 'position', 'grid', 'to', 'allow', 'daily', 'positions', 'to', 'be', 'shown', 'directly', 'above', 'monthly', 'positions']\n","Ligne  24 vaut ['each', 'grouped', 'column', 'in', 'the', 'top', 'grid', 'would', 'be', 'tied', 'to', 'a', 'grouped', 'column', 'in', 'the', 'bottom', 'grid']\n","Ligne  25 vaut ['ability', 'to', 'properly', 'show', 'curve', 'shift', 'for', 'float', 'for', 'float', 'deals', 'determine', 'the', 'appropriate', 'positions', 'to', 'show', 'for', 'each', 'gas', 'daily', 'for', 'monthly', 'index', 'physical', 'gas', 'for', 'nymex', 'physical', 'gas', 'for', 'inside', 'ferc', 'physical', 'gas', 'for', 'mid', 'market']\n","Ligne  26 vaut ['ability', 'for', 'tds', 'to', 'pull', 'valuation', 'results', 'based', 'on', 'a', 'tds', 'flag', 'instead', 'of', 'using', 'official', 'valuations']\n","Ligne  27 vaut ['position', 'and', 'p', 'l', 'aggregation', 'across', 'all', 'gas', 'desks']\n","Ligne  28 vaut ['ability', 'to', 'include', 'the', 'gas', 'price', 'book', 'into', 'tds', 'inclusion', 'of', 'spread', 'options', 'in', 'our', 'systems']\n","Ligne  29 vaut ['ability', 'to', 'handle', 'volatility', 'skew', 'and', 'correlations']\n","Ligne  30 vaut ['ability', 'to', 'revalue', 'all', 'options', 'incrementally', 'throughout', 'the', 'trading', 'day']\n","Ligne  31 vaut ['approximate', 'delta', 'changes', 'between', 'valuations', 'using', 'instantaneous', 'gamma', 'or', 'a', 'gamma', 'grid']\n","Ligne  32 vaut ['valuation', 'of', 'gas', 'daily', 'options']\n","Ligne  33 vaut ['a', 'new', 'position', 'screen', 'for', 'options', 'months', 'x', 'strike', 'x', 'delta']\n","Ligne  35 vaut ['inclusion', 'of', 'positions', 'for', 'exotic', 'options', 'currently', 'managed', 'in', 'spreadsheets']\n","Ligne  36 vaut ['ability', 'to', 'isolate', 'the', 'position', 'change', 'due', 'to', 'changed', 'deals', 'in', 'the', 'position', 'manager']\n","Ligne  37 vaut ['ability', 'to', 'view', 'change', 'deal', 'p', 'l', 'in', 'the', 'tds', 'deal', 'ticker']\n","Ligne  38 vaut ['show', 'new', 'deal', 'terms', 'prior', 'deal', 'terms', 'and', 'net', 'p', 'l', 'affect', 'of', 'the', 'change']\n","Ligne  39 vaut ['eliminate', 'change', 'deals', 'with', 'no', 'economic', 'impact', 'from', 'the', 'tds', 'deal', 'ticker']\n","Ligne  40 vaut ['position', 'drill', 'down', 'in', 'the', 'position', 'manager', 'to', 'isolate', 'the', 'impact', 'of', 'individual', 'deals', 'on', 'the', 'position', 'total', 'in', 'a', 'grid', 'cell']\n","Ligne  42 vaut ['deployment', 'of', 'tds', 'in', 'canada']\n","Ligne  43 vaut ['currency', 'and', 'volume', 'uom', 'conversions']\n","Ligne  44 vaut ['implicit', 'and', 'explicit', 'position', 'break', 'out', 'issues']\n","Ligne  46 vaut ['ps', 'colleen', 'is', 'setting', 'up', 'a', 'meeting', 'tomorrow', 'to', 'discuss', 'the', 'direction', 'for', 'transport']\n","Ligne  47 vaut ['hopefully', 'well', 'know', 'much', 'better', 'where', 'that', 'part', 'stands', 'at', 'that', 'point']\n","summary :\n","\n"," [\"', 'Customized rows and columns in the position manager (ad hoc rows/columns that ', 'add up existing position manager rows/columns).\", \"', 'Inclusion of positions for exotic options currently managed in spreadsheets.\", \"', 'Ability to isolate the position change due to changed deals in the position ', 'manager.\"]\n"]}]},{"cell_type":"markdown","metadata":{"id":"IjvFt1AbRNBS"},"source":["# SPACY - NER"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"PYcF03C2v-Pt","executionInfo":{"status":"ok","timestamp":1655911062734,"user_tz":-120,"elapsed":70832,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"outputs":[],"source":["deb = 0\n","fin = df_emails.shape[0]\n","for x in range(deb,fin):\n","# subject\n","  subj = df_emails.iloc[x]['header']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_header'][x] = doc_subj.ents\n","\n","# body\n","  subj = df_emails.iloc[x]['body']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_body'][x] = doc_subj.ents"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"NyAzFKn7X2uO","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1655911062740,"user_tz":-120,"elapsed":21,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"c784c9d3-6411-4627-a171-b8f3f6cb5a9f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                 header      NER_header  \\\n","20                                  NaN              ()   \n","21           Re: Not business related..              ()   \n","22      Re: Original Sept check/closing              ()   \n","23                       San Juan Index  ((San, Juan),)   \n","24                       San Juan Index  ((San, Juan),)   \n","25                 Investment Structure              ()   \n","26                 Investment Structure              ()   \n","27                                  NaN              ()   \n","28                                  NaN              ()   \n","29       Re: Gas Trading Vision meeting              ()   \n","30                                  NaN              ()   \n","31      Gas Physical/Financial Position              ()   \n","32                              closing              ()   \n","33                                  NaN              ()   \n","34                                  NaN              ()   \n","35                                  NaN              ()   \n","36                                  NaN              ()   \n","37                                  NaN              ()   \n","38                                  NaN              ()   \n","39                                  NaN              ()   \n","40                                  NaN              ()   \n","41  Westgate Proforma-Phillip Allen.xls              ()   \n","42                                  NaN              ()   \n","43                                  NaN              ()   \n","44                           Re: burnet              ()   \n","\n","                                             NER_body  \n","20                    ((Brenda), (second), (October))  \n","21                                        ((Fletch),)  \n","22                    ((Brenda), (second), (October))  \n","23  ((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...  \n","24  ((yesterday), (El, Paso), (San, Juan), (monthl...  \n","25  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...  \n","26  ((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...  \n","27  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","28                            ((Reagan), (12), (FHA))  \n","29                                         ((Nymex),)  \n","30  ((Phillip, K, Allen, /, HOU, /, ECT), (Richard...  \n","31  ((Phillip, K, Allen, /, HOU, /, ECT), (12:07, ...  \n","32  ((Phillip, K, Allen, /, HOU, /, ECT), (11:57, ...  \n","33                           ((Chris), (PG&E), (EOL))  \n","34  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","35  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","36                                         ((Keith),)  \n","37  ((daily), (Mike, Grigsby), (37031), (today), (...  \n","38  ((Denver), (2002), (2003), (25,000), (2004), (...  \n","39      ((Jim), (weekly), (California), (this, week))  \n","40  ((Keith), (700,000), (max), (Creekside, Builde...  \n","41  ((Phillip, K, Allen, /, HOU, /, ECT), (04:35, ...  \n","42  ((Reagan), (', 1308/1308), (2.7), (Cherry, Cre...  \n","43                                          ((Jeff),)  \n","44                     ((Jeff), (Brenda, Key, Stone))  "],"text/html":["\n","  <div id=\"df-fc092086-de6c-4b0d-90d2-a2ea490abe6e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>header</th>\n","      <th>NER_header</th>\n","      <th>NER_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Re: Not business related..</td>\n","      <td>()</td>\n","      <td>((Fletch),)</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Re: Original Sept check/closing</td>\n","      <td>()</td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>San Juan Index</td>\n","      <td>((San, Juan),)</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>San Juan Index</td>\n","      <td>((San, Juan),)</td>\n","      <td>((yesterday), (El, Paso), (San, Juan), (monthl...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Investment Structure</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Investment Structure</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Reagan), (12), (FHA))</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Re: Gas Trading Vision meeting</td>\n","      <td>()</td>\n","      <td>((Nymex),)</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (Richard...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Gas Physical/Financial Position</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (12:07, ...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>closing</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (11:57, ...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Chris), (PG&amp;E), (EOL))</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Keith),)</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((daily), (Mike, Grigsby), (37031), (today), (...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Denver), (2002), (2003), (25,000), (2004), (...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Jim), (weekly), (California), (this, week))</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Keith), (700,000), (max), (Creekside, Builde...</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Westgate Proforma-Phillip Allen.xls</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (04:35, ...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Reagan), (', 1308/1308), (2.7), (Cherry, Cre...</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Jeff),)</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Re: burnet</td>\n","      <td>()</td>\n","      <td>((Jeff), (Brenda, Key, Stone))</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc092086-de6c-4b0d-90d2-a2ea490abe6e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc092086-de6c-4b0d-90d2-a2ea490abe6e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc092086-de6c-4b0d-90d2-a2ea490abe6e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["df_emails[['header','NER_header','NER_body']][20:45]\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"23GUNvjEcvjP","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1655911062741,"user_tz":-120,"elapsed":16,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"250b9431-a01d-4512-fc91-34d5a2b8de15"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/spacy/displacy/__init__.py:205: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n","  warnings.warn(Warnings.W006)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Re: burnet</div></span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----- eMail  44  -----\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">['', '\n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Jeff\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",",', '', ' I need to see the site plan for Burnet.  Remember I must get written ', 'approval from \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Brenda Key Stone\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," before I can sell this property and she has ', 'concerns about the way the property will be subdivided.    I would also like ', 'to review the closing statements as soon as possible.', '', 'Phillip']</div></span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n"]}],"source":["id = 44\n","doc= nlp(df_emails['header'][id])\n","displacy.render(doc, style = \"ent\",jupyter = True)\n","print(\"----- eMail \",id,\" -----\")\n","doc= nlp(df_emails['body'][id])\n","displacy.render(doc, style = \"ent\",jupyter = True)\n","print(\"\\n\")\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"LgS5AAxWhsnK","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1655911063217,"user_tz":-120,"elapsed":488,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"2342960b-e1a7-47f9-92ef-76d40a34f5ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'People, including fictional'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["spacy.explain(\"PERSON\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"P6Px81DsaBEj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655911063218,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"ee407dc0-e648-4c39-a352-1f13577c79d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["header                                               Re: burnet\n","NER_header                                                   ()\n","body          ['', 'Jeff,', '', ' I need to see the site pla...\n","NER_body                         ((Jeff), (Brenda, Key, Stone))\n","Name: 44, dtype: object"]},"metadata":{},"execution_count":23}],"source":["# A ce stade le fichier a la structure attendue par melusine + l'identification des NER par Spacy\n","df_emails[['header','NER_header','body','NER_body']].iloc[id]"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"HjkOEh1BlpSw","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1655911063219,"user_tz":-120,"elapsed":25,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"f511f6f3-c592-4a9b-bde3-da80e84ada0d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"['', 'Jeff,', '', ' I need to see the site plan for Burnet.  Remember I must get written ', 'approval from Brenda Key Stone before I can sell this property and she has ', 'concerns about the way the property will be subdivided.    I would also like ', 'to review the closing statements as soon as possible.', '', 'Phillip']\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["df_emails['body'].iloc[id]"]},{"cell_type":"markdown","source":["# Summary"],"metadata":{"id":"gScc6J-L5m6L"}},{"cell_type":"code","source":["df_emails[['body','body_dict','summary','NER_body']]"],"metadata":{"id":"DaUrJQ7lDqlq","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1655911484794,"user_tz":-120,"elapsed":360,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"38643d38-ed4a-4d07-91c0-584f8fcc0ed0"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  body  \\\n","0                ['', 'Here is our forecast', '', ' ']   \n","1    ['', 'Traveling to have a business meeting tak...   \n","2               ['', 'test successful.  way to go!!!']   \n","3    ['', 'Randy,', '', ' Can you send me a schedul...   \n","4          ['', \"Let's shoot for Tuesday at 11:45.  \"]   \n","..                                                 ...   \n","995  ['', 'Jerilyn,', '', 'Call or email with addit...   \n","996  ['', '', '', ' -----Original Message-----', 'F...   \n","997  ['', 'Kay,', '', \"I sent a copy of an article ...   \n","998  ['', '', '', ' -----Original Message-----', 'F...   \n","999  ['', '', '', ' -----Original Message-----', 'F...   \n","\n","                                             body_dict  \\\n","0                                                   {}   \n","1    {0: ['traveling', 'to', 'have', 'a', 'business...   \n","2                                                   {}   \n","3    {0: ['randy', 'can', 'you', 'send', 'me', 'a',...   \n","4       {0: ['lets', 'shoot', 'for', 'tuesday', 'at']}   \n","..                                                 ...   \n","995  {0: ['jerilyn', 'call', 'or', 'email', 'with',...   \n","996  {0: ['original', 'message', 'from', 'tjeff', '...   \n","997  {0: ['kay', 'i', 'sent', 'a', 'copy', 'of', 'a...   \n","998  {0: ['original', 'message', 'from', 'tjacquest...   \n","999  {0: ['original', 'message', 'from', 'tjeff', '...   \n","\n","                                               summary  \\\n","0                                                   []   \n","1    [['', 'Traveling to have a business meeting ta...   \n","2                                                   []   \n","3    [['', 'Randy,', '', ' Can you send me a schedu...   \n","4        [['', \"Let's shoot for Tuesday at 11:45.  \"]]   \n","..                                                 ...   \n","995  [['', 'Jerilyn,', '', 'Call or email with addi...   \n","996  [['', '', '', ' -----Original Message-----', '...   \n","997  [Each day they post candid pictures from the p...   \n","998  [['', '', '', ' -----Original Message-----', '...   \n","999  [['', '', '', ' -----Original Message-----', '...   \n","\n","                                              NER_body  \n","0                                                   ()  \n","1                                          ((Austin),)  \n","2                                                   ()  \n","3                                ((Randy), (Patti, S))  \n","4                                 ((Tuesday), (11:45))  \n","..                                                 ...  \n","995                             ((Jerilyn), (Phillip))  \n","996  ((12:58, PM, '), (Phillip, K., '), (Southern, ...  \n","997  ((Kay), (Gary), (one), (dozens), (Kelsey), (Ba...  \n","998  ((June, 27, ,, 2001), (6:08, AM, '), (Phillip,...  \n","999  ((9:26, AM, '), (Phillip, K., '), (Jacques), (...  \n","\n","[1000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-79080f00-22e7-4d9a-ae11-6e913b1e3ab0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>body</th>\n","      <th>body_dict</th>\n","      <th>summary</th>\n","      <th>NER_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['', 'Here is our forecast', '', ' ']</td>\n","      <td>{}</td>\n","      <td>[]</td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['', 'Traveling to have a business meeting tak...</td>\n","      <td>{0: ['traveling', 'to', 'have', 'a', 'business...</td>\n","      <td>[['', 'Traveling to have a business meeting ta...</td>\n","      <td>((Austin),)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['', 'test successful.  way to go!!!']</td>\n","      <td>{}</td>\n","      <td>[]</td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['', 'Randy,', '', ' Can you send me a schedul...</td>\n","      <td>{0: ['randy', 'can', 'you', 'send', 'me', 'a',...</td>\n","      <td>[['', 'Randy,', '', ' Can you send me a schedu...</td>\n","      <td>((Randy), (Patti, S))</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['', \"Let's shoot for Tuesday at 11:45.  \"]</td>\n","      <td>{0: ['lets', 'shoot', 'for', 'tuesday', 'at']}</td>\n","      <td>[['', \"Let's shoot for Tuesday at 11:45.  \"]]</td>\n","      <td>((Tuesday), (11:45))</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>['', 'Jerilyn,', '', 'Call or email with addit...</td>\n","      <td>{0: ['jerilyn', 'call', 'or', 'email', 'with',...</td>\n","      <td>[['', 'Jerilyn,', '', 'Call or email with addi...</td>\n","      <td>((Jerilyn), (Phillip))</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>['', '', '', ' -----Original Message-----', 'F...</td>\n","      <td>{0: ['original', 'message', 'from', 'tjeff', '...</td>\n","      <td>[['', '', '', ' -----Original Message-----', '...</td>\n","      <td>((12:58, PM, '), (Phillip, K., '), (Southern, ...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>['', 'Kay,', '', \"I sent a copy of an article ...</td>\n","      <td>{0: ['kay', 'i', 'sent', 'a', 'copy', 'of', 'a...</td>\n","      <td>[Each day they post candid pictures from the p...</td>\n","      <td>((Kay), (Gary), (one), (dozens), (Kelsey), (Ba...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>['', '', '', ' -----Original Message-----', 'F...</td>\n","      <td>{0: ['original', 'message', 'from', 'tjacquest...</td>\n","      <td>[['', '', '', ' -----Original Message-----', '...</td>\n","      <td>((June, 27, ,, 2001), (6:08, AM, '), (Phillip,...</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>['', '', '', ' -----Original Message-----', 'F...</td>\n","      <td>{0: ['original', 'message', 'from', 'tjeff', '...</td>\n","      <td>[['', '', '', ' -----Original Message-----', '...</td>\n","      <td>((9:26, AM, '), (Phillip, K., '), (Jacques), (...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79080f00-22e7-4d9a-ae11-6e913b1e3ab0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-79080f00-22e7-4d9a-ae11-6e913b1e3ab0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-79080f00-22e7-4d9a-ae11-6e913b1e3ab0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]}],"metadata":{"colab":{"collapsed_sections":["IjvFt1AbRNBS"],"name":"Py_Easymail.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}