{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'sender', 'recipient1', 'subject', 'text'], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chemin=r\"/Users/franckglastre/\"\n",
    "df=pd.read_csv(chemin+\"emaildata_100000_0.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"\".join(df.text[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'\\', \\'---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/09/2000 \\', \\'02:16 PM ---------------------------\\', \\'\\', \\'\\', \\'Richard Burchfield\\', \\'10/06/2000 06:59 AM\\', \\'To: Phillip K Allen/HOU/ECT@ECT\\', \\'cc: Beth Perlman/HOU/ECT@ECT \\', \\'Subject: Consolidated positions: Issues & To Do list\\', \\'\\', \\'Phillip,\\', \\' Below is the issues & to do list as we go forward with documenting the \\', \\'requirements for consolidated physical/financial positions and transport \\', \"trade capture. What we need to focus on is the first bullet in Allan\\'s list; \", \\'the need for a single set of requirements. Although the meeting with Keith, \\', \\'on Wednesday,  was informative the solution of creating a infinitely dynamic \\', \\'consolidated position screen, will be extremely difficult and time \\', \\'consuming.  Throughout the meeting on Wednesday, Keith alluded to the \\', \\'inability to get consensus amongst the traders on the presentation of the \\', \\'consolidated position, so the solution was to make it so that a trader can \\', \\'arrange the position screen to their liking (much like Excel). What needs to \\', \\'happen on Monday from 3 - 5 is a effort to design a desired layout for the \\', \\'consolidated position screen, this is critical. This does not exclude \\', \\'building a capability to create a more flexible position presentation for the \\', \\'future, but in order to create a plan that can be measured we need firm \\', \\'requirements. Also, to reiterate that the goals of this project is a project \\', \\'plan on consolidate physical/financial positions and transport trade capture. \\', \\'The other issues that have been raised will be capture as projects on to \\', \\'themselves, and will need to be prioritised as efforts outside of this \\', \\'project.\\', \\'\\', \\'I have been involved in most of the meetings and the discussions have been \\', \\'good. I believe there has been good communication between the teams, but now \\', \\'we need to have focus on the objectives we set out to solve.\\', \\'\\', \\'Richard  \\', \\'---------------------- Forwarded by Richard Burchfield/HOU/ECT on 10/06/2000 \\', \\'08:34 AM ---------------------------\\', \\'\\', \\'\\', \\'Allan Severude\\', \\'10/05/2000 06:03 PM\\', \\'To: Richard Burchfield/HOU/ECT@ECT\\', \\'cc: Peggy Alix/HOU/ECT@ECT, Russ Severson/HOU/ECT@ECT, Scott \\', \\'Mills/HOU/ECT@ECT, Kenny Ha/HOU/ECT@ECT \\', \\'Subject: Consolidated positions: Issues & To Do list\\', \\'\\', \\'\\', \\'From our initial set of meetings with the traders regarding consolidated \\', \\'positions, I think we still have the following issues:\\', \"We don\\'t have a single point of contact from the trading group.  We\\'ve had \", \\'three meetings which brought out very different issues from different \\', \\'traders.  We really need a single point of contact to help drive the trader \\', \\'requirements and help come to a consensus regarding the requirements.\\', \"We\\'re getting hit with a lot of different requests, many of which appear to \", \\'be outside the scope of position consolidation.\\', \\'\\', \\'Things left to do:\\', \\'I think it may be useful to try to formulate a high level project goal to \\', \"make it as clear as possible what we\\'re trying to accomplish with this \", \"project.  It\\'ll help determine which requests fall under the project scope.\", \\'Go through the list of requests to determine which are in scope for this \\', \\'project and which fall out of scope.\\', \\'For those in scope, work to define relative importance (priority) of each and \\', \\'work with traders to define the exact requirements of each.\\', \\'Define the desired lay out of the position manager screen: main view and all \\', \\'drill downs.\\', \\'Use the above to formulate a project plan.\\', \\'\\', \\'Things requested thus far (no particular order):\\', \\'Inclusion of Sitara physical deals into the TDS position manager and deal \\', \\'ticker.\\', \\'Customized rows and columns in the position manager (ad hoc rows/columns that \\', \\'add up existing position manager rows/columns).\\', \\'New drill down in the position manager to break out positions by: physical, \\', \\'transport, swaps, options, ...\\', \\'Addition of a curve tab to the position manager to show the real-time values \\', \\'of all curves on which the desk has a position.\\', \\'Ability to split the current position grid to allow daily positions to be \\', \\'shown directly above monthly positions.  Each grouped column in the top grid \\', \\'would be tied to a grouped column in the bottom grid.\\', \\'Ability to properly show curve shift for float-for-float deals; determine the \\', \\'appropriate positions to show for each:\\', \\'Gas Daily for monthly index,\\', \\'Physical gas for Nymex,\\', \\'Physical gas for Inside Ferc,\\', \\'Physical gas for Mid market.\\', \\'Ability for TDS to pull valuation results based on a TDS flag instead of \\', \\'using official valuations.\\', \\'Position and P&L aggregation across all gas desks.\\', \\'Ability to include the Gas Price book into TDS:\\', \\'Inclusion of spread options in our systems.  Ability to handle volatility \\', \\'skew and correlations.\\', \\'Ability to revalue all options incrementally throughout the trading day.  \\', \\'Approximate delta changes between valuations using instantaneous gamma or a \\', \\'gamma grid.\\', \\'Valuation of Gas Daily options.\\', \\'A new position screen for options (months x strike x delta).  TBD.\\', \\'Inclusion of positions for exotic options currently managed in spreadsheets.\\', \\'Ability to isolate the position change due to changed deals in the position \\', \\'manager.\\', \\'Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms, \\', \\'prior deal terms, and net P&L affect of the change.\\', \\'Eliminate change deals with no economic impact from the TDS deal ticker.\\', \\'Position drill down in the position manager to isolate the impact of \\', \\'individual deals on the position total in a grid cell.\\', \\'Benchmark positions in TDS.\\', \\'Deployment of TDS in Canada. Currency and volume uom conversions. Implicit \\', \\'and explicit position break out issues.\\', \\'\\', \\'-- Allan.\\', \\'\\', \\'PS: Colleen is setting up a meeting tomorrow to discuss the direction for \\', \"transport.  Hopefully we\\'ll know much better where that part stands at that \", \\'point.\\', \\'\\', \\'\\', \\'\\', \\'\\', \\'\\']'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/09/2000  02:16 PM ---------------------------   Richard Burchfield 10/06/2000 06:59 AM To: Phillip K Allen/HOU/ECT@ECT cc: Beth Perlman/HOU/ECT@ECT  Subject: Consolidated positions: Issues & To Do list  Phillip  Below is the issues & to do list as we go forward with documenting the  requirements for consolidated physical/financial positions and transport  trade capture. What we need to focus on is the first bullet in Allans list;  the need for a single set of requirements. Although the meeting with Keith  on Wednesday  was informative the solution of creating a infinitely dynamic  consolidated position screen will be extremely difficult and time  consuming.  Throughout the meeting on Wednesday Keith alluded to the  inability to get consensus amongst the traders on the presentation of the  consolidated position so the solution was to make it so that a trader can  arrange the position screen to their liking (much like Excel). What needs to  happen on Monday from 3 - 5 is a effort to design a desired layout for the  consolidated position screen this is critical. This does not exclude  building a capability to create a more flexible position presentation for the  future but in order to create a plan that can be measured we need firm  requirements. Also to reiterate that the goals of this project is a project  plan on consolidate physical/financial positions and transport trade capture.  The other issues that have been raised will be capture as projects on to  themselves and will need to be prioritised as efforts outside of this  project.  I have been involved in most of the meetings and the discussions have been  good. I believe there has been good communication between the teams but now  we need to have focus on the objectives we set out to solve.  Richard   ---------------------- Forwarded by Richard Burchfield/HOU/ECT on 10/06/2000  08:34 AM ---------------------------   Allan Severude 10/05/2000 06:03 PM To: Richard Burchfield/HOU/ECT@ECT cc: Peggy Alix/HOU/ECT@ECT Russ Severson/HOU/ECT@ECT Scott  Mills/HOU/ECT@ECT Kenny Ha/HOU/ECT@ECT  Subject: Consolidated positions: Issues & To Do list   From our initial set of meetings with the traders regarding consolidated  positions I think we still have the following issues: We dont have a single point of contact from the trading group.  Weve had  three meetings which brought out very different issues from different  traders.  We really need a single point of contact to help drive the trader  requirements and help come to a consensus regarding the requirements. Were getting hit with a lot of different requests many of which appear to  be outside the scope of position consolidation.  Things left to do: I think it may be useful to try to formulate a high level project goal to  make it as clear as possible what were trying to accomplish with this  project.  Itll help determine which requests fall under the project scope. Go through the list of requests to determine which are in scope for this  project and which fall out of scope. For those in scope work to define relative importance (priority) of each and  work with traders to define the exact requirements of each. Define the desired lay out of the position manager screen: main view and all  drill downs. Use the above to formulate a project plan.  Things requested thus far (no particular order): Inclusion of Sitara physical deals into the TDS position manager and deal  ticker. Customized rows and columns in the position manager (ad hoc rows/columns that  add up existing position manager rows/columns). New drill down in the position manager to break out positions by: physical  transport swaps options ... Addition of a curve tab to the position manager to show the real-time values  of all curves on which the desk has a position. Ability to split the current position grid to allow daily positions to be  shown directly above monthly positions.  Each grouped column in the top grid  would be tied to a grouped column in the bottom grid. Ability to properly show curve shift for float-for-float deals; determine the  appropriate positions to show for each: Gas Daily for monthly index Physical gas for Nymex Physical gas for Inside Ferc Physical gas for Mid market. Ability for TDS to pull valuation results based on a TDS flag instead of  using official valuations. Position and P&L aggregation across all gas desks. Ability to include the Gas Price book into TDS: Inclusion of spread options in our systems.  Ability to handle volatility  skew and correlations. Ability to revalue all options incrementally throughout the trading day.   Approximate delta changes between valuations using instantaneous gamma or a  gamma grid. Valuation of Gas Daily options. A new position screen for options (months x strike x delta).  TBD. Inclusion of positions for exotic options currently managed in spreadsheets. Ability to isolate the position change due to changed deals in the position  manager. Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms  prior deal terms and net P&L affect of the change. Eliminate change deals with no economic impact from the TDS deal ticker. Position drill down in the position manager to isolate the impact of  individual deals on the position total in a grid cell. Benchmark positions in TDS. Deployment of TDS in Canada. Currency and volume uom conversions. Implicit  and explicit position break out issues.  -- Allan.  PS: Colleen is setting up a meeting tomorrow to discuss the direction for  transport.  Hopefully well know much better where that part stands at that  point.     ]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "r = re.compile(r\"[\\\\\\''\\\",]\")\n",
    "txt = df.text[12]\n",
    "print(r.sub('', txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def TF(token, artikle):\n",
    "    \"\"\"\n",
    "    Calcule le score TF d'un mot dans un artikle\n",
    "    \n",
    "    token : Mot dont le score TF doit être calculé.\n",
    "    \n",
    "    artikle : Dictionnaire généré à partir d'un texte.\n",
    "    \"\"\"\n",
    "    f = 0\n",
    "    for key in artikle:\n",
    "        for work in artikle[key]:\n",
    "            if work == token:\n",
    "                f += 1 \n",
    "    return np.log(f+1)\n",
    "\n",
    "def IDF(token, corpus):\n",
    "    \"\"\"\n",
    "    Calcule le score IDF d'un mot dans un corpus d'artikles.\n",
    "    \n",
    "    token : Mot dont le score IDF doit être calculé.\n",
    "    \n",
    "    corpus : Liste d'artikles.\n",
    "    \"\"\"\n",
    "    N = len(corpus)\n",
    "    d=0\n",
    "    present = False\n",
    "    \n",
    "    for artikle in corpus:\n",
    "        for key in artikle:\n",
    "            if token in artikle[key]:\n",
    "                present = True\n",
    "        d += int(present)\n",
    "        present = False\n",
    "                \n",
    "    return np.log(N/(d+1) +1)\n",
    "\n",
    "def TFIDF(token, artikle, corpus):\n",
    "    \"\"\"\n",
    "    Calcule le score TF-IDF d'un mot dans un texte.\n",
    "    \n",
    "    token : mot dont le score doit être calculé.\n",
    "    \n",
    "    artikle : artikle qui servira à calculer le score du mot dans cet artikle.\n",
    "    \n",
    "    corpus : Liste d'artikles formant le corpus.\n",
    "    \"\"\"\n",
    "    return TF(token, artikle)*IDF(token, corpus)\n",
    "\n",
    "def score_sentence(corpus, artikle, sentence):\n",
    "    \"\"\"\n",
    "    Calcule le score d'une phrase.\n",
    "    \n",
    "    corpus : Liste d'artikles.\n",
    "    \n",
    "    artikle : Dictionnaire de phrases.\n",
    "    \n",
    "    sentence : Phrase sous forme de liste de mots.\n",
    "    \"\"\"\n",
    "    score_sentence = []\n",
    "    for word in sentence :\n",
    "        score_word = TFIDF(word, artikle, corpus)\n",
    "        score_sentence.append(score_word)\n",
    "    return np.mean(score_sentence)\n",
    "\n",
    "def best_sentences(scores_artikle, nb_sentences):\n",
    "    \"\"\"\n",
    "    Retourne les indices des phrases les plus importantes en fonction des scores obtenus.\n",
    "    \n",
    "    scores_artikle : Liste des scores de chaque phrase dans un texte.\n",
    "    \n",
    "    nb_sentences : Nombre de phrases à sélectionner.\n",
    "    \"\"\"\n",
    "    \n",
    "    return sorted(np.argsort(scores_artikle)[-nb_sentences:])\n",
    "\n",
    "def summarize(i, n_sentences, df):\n",
    "    \"\"\"\n",
    "    Synthèse extractive d'un article par la méthode TF-IDF.\n",
    "    \n",
    "    i : indice de l'article dans le corpus.\n",
    "    \n",
    "    n_sentences : nombre de phrases à conserver.\n",
    "    \n",
    "    df : DataFrame contenant les artikles dans une colonne 'Artikle'.    \n",
    "    \"\"\"\n",
    "    corpus = df[\"text\"]\n",
    "    artikle = list(corpus[i])\n",
    "    \n",
    "    \n",
    "    # Calcul du score de chaque phrase de l'artikle\n",
    "    #scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle.values()]\n",
    "    scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle]\n",
    "    \n",
    "    # Extraction des indices des phrases ayant les meilleurs scores\n",
    "    result = best_sentences(scores_artikle, n_sentences)\n",
    "    \n",
    "    # Séparation de phrases l'article original \n",
    "    tokenized_article = sent_tokenize(artikle[i])\n",
    "    \n",
    "    # Extraction des phrases les plus importantes\n",
    "    summary = [tokenized_article[i] for i in result]\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifier la cellule texte pour qu'elle contienne une liste et non pas une string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-c98e41343946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(\"The Reference\\n\",*reference, '\\n\\n Our Summary \\n', *summary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-e6b413408a5e>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(i, n_sentences, df)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Calcul du score de chaque phrase de l'artikle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle.values()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mscores_artikle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Extraction des indices des phrases ayant les meilleurs scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-e6b413408a5e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Calcul du score de chaque phrase de l'artikle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle.values()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mscores_artikle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Extraction des indices des phrases ayant les meilleurs scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-e6b413408a5e>\u001b[0m in \u001b[0;36mscore_sentence\u001b[0;34m(corpus, artikle, sentence)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mscore_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mscore_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mscore_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-e6b413408a5e>\u001b[0m in \u001b[0;36mTFIDF\u001b[0;34m(token, artikle, corpus)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mListe\u001b[0m \u001b[0md\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0martikles\u001b[0m \u001b[0mformant\u001b[0m \u001b[0mle\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-e6b413408a5e>\u001b[0m in \u001b[0;36mTF\u001b[0;34m(token, artikle)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martikle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwork\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "summary = word_tokenize(\" \".join(summarize(12, 3, df)))\n",
    "\n",
    "#print(\"The Reference\\n\",*reference, '\\n\\n Our Summary \\n', *summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the rentrolls:\n"
     ]
    }
   ],
   "source": [
    "corpus = df[\"text\"]\n",
    "artikle = corpus[11]\n",
    "artikle=artikle.split(\"', '\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
