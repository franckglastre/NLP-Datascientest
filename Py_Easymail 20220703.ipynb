{"cells":[{"cell_type":"markdown","metadata":{"id":"-ZKemb11VlJD"},"source":["# Structuration DataSet (A ne plus relancer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8u5xskFVyMI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc93a1a5-fccf-4be8-9bc9-86f3b809cfbc","executionInfo":{"status":"ok","timestamp":1656934950292,"user_tz":-120,"elapsed":62668,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","(405968, 6)\n","(227032, 5)\n"]}],"source":["# Mount GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# On concaténe les 6 fichiers\n","import pandas as pd\n","df_0 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_0.csv\")\n","df_1 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_1.csv\")\n","df_2 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_2.csv\")\n","df_3 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_3.csv\")\n","df_4 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_4.csv\")\n","df_5 = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/emaildata_100000_5.csv\")\n","# df = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron.csv\", nrows=1500)\n","frames = [df_0,df_1,df_2,df_3,df_4,df_5]\n","df = pd.concat(frames)\n","# la selection ci-dessous a permis de détecter 3 doublons (toutes colonnes identiques)\n","# df = df.loc[(df['subject'] == \"Sagewood Town Homes\")]\n","print(df.shape)\n","# df = df_emails.loc[(df['subject'] == \"Sagewood Town Homes\")]\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","# suppression des doublons (sur toutes les colonnes sauf index)\n","df.drop_duplicates(subset=['date','sender', 'recipient1', 'subject','text'],keep = 'first', inplace=True)\n","# on renomme les colonnes\n","df = df.rename(columns={'sender': 'from', 'recipient1': 'to','subject': 'header', 'text': 'body'})\n","# et export en csv du résultat.\n","file_name = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique.csv\"\n","df.to_csv(file_name, encoding='utf-8', index=False)\n","print(df.shape)\n","# Taille du fichier divisée par 2 environ\n","# génération d'un fichier light de 1000 lignes pour traitements plus rapides.\n","file_name = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique_1000.csv\"\n","df_emails.to_csv(file_name, encoding='utf-8', index=False)"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"nNnzrRL6jUth"}},{"cell_type":"markdown","source":["# Import - Data Preprocessing structures"],"metadata":{"id":"AQ7Tk9bJn1Gw"}},{"cell_type":"markdown","source":["Mount Gdrive files"],"metadata":{"id":"eJjM6VrgnyRB"}},{"cell_type":"code","source":["# Mount GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"11nFmkc8jQid","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658319673381,"user_tz":-120,"elapsed":13999,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"d3bcd4b6-0452-4ba7-ef07-474c1188d5f3"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Import Spacy"],"metadata":{"id":"LMLChWfRntBA"}},{"cell_type":"code","source":["#!pip install -U spacy\n","#!python -m spacy download en_core_web_sm\n","# ligne ci-dessous a réexecuter ssi reinit du notebook\n","!pip install spacy-transformers"],"metadata":{"id":"C3maunlQnoaB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf2152bb-81ea-40a5-d6d0-2cffb528f8ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.7/dist-packages (1.1.7)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (2.4.3)\n","Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (0.8.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (1.12.0+cu113)\n","Requirement already satisfied: spacy<4.0.0,>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (3.3.1)\n","Requirement already satisfied: transformers<4.21.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (4.20.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.0.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.23.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.9.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.6.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.0.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.7.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (21.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (4.1.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (8.0.17)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (57.4.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.21.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.11.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.8.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.4.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.1.3->spacy-transformers) (3.8.0)\n"]}]},{"cell_type":"code","source":["import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","stopwords=list(STOP_WORDS)\n","from string import punctuation\n","punctuation=punctuation+ '\\n'\n"],"metadata":{"id":"Ohg4nEgBB_7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_giUgOlhsiSj"},"outputs":[],"source":["import pandas as pd\n","# Pour limiter les temps de calcul on travaille uniquement sur les 'nrows' premiers mails\n","df_emails = pd.read_csv(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique_1000.csv\", nrows=1000)\n","df_emails.head()"]},{"cell_type":"markdown","source":["Overview dataset"],"metadata":{"id":"ZUe59jgo7hYh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7uLPAsx-tPfL"},"outputs":[],"source":["# nbre d'expéditeurs distincts\n","len(df_emails['from'].unique())"]},{"cell_type":"code","source":["# nbre de destinataires distincts\n","len(df_emails['to'].unique())"],"metadata":{"id":"9itN2Crz6yKN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Rajout colonnes pour traitements ultérieurs"],"metadata":{"id":"HoTFvyJi7tpd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"geS2lCMeIpwf"},"outputs":[],"source":["import numpy as np\n","df_emails = df_emails.replace('NaN', np.NaN)\n","# df_emails = df[df['header'].notna()]\n","\n","df_emails['cc'] = ''                        # pour identfication des personnes en copie\n","df_emails['NER_header'] = ''                # Spacy NER\n","df_emails['NER_body'] = ''                  # Spacy NER\n","df_emails['body_clean'] = ''                # body sans caracteres parasites\n","df_emails['body_dict'] = ''                 # body tokenisé\n","df_emails['summary_TFIDF'] = ''             # extractive summary by TF-IDF\n","df_emails['summary_TFIDF_sim'] = ''         # calcul de similarité par rapport à body_clean\n","df_emails['summary_spacy'] = ''             # extractive summary by Spacy\n","df_emails['summary_spacy_sim'] = ''         # calcul de similarité par rapport à body_clean\n","df_emails['summary_abstractive'] = ''       # abstractive summary by HugginFace/BERT\n","df_emails['summary_abstractive_sim'] = ''   # calcul de similarité par rapport à body_clean\n","df_emails['best_sim'] = ''                  # meilleure taux de similarité par rapport à body_clean\n","df_emails.info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yh4-upAdXbSS"},"outputs":[],"source":["#\n","# A ce stade le fichier a la structure nécessaire à Melusine pour le nettoyage\n","#"]},{"cell_type":"markdown","source":["# NER with Spacy"],"metadata":{"id":"hYIaLzOZxTLL"}},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_sm')\n","spacy_stopwords = nlp.Defaults.stop_words\n","stopwords = spacy_stopwords\n","print(spacy_stopwords)\n","\n","\n","deb = 0\n","fin = df_emails.shape[0]\n","for x in range(deb,fin):\n","# subject\n","  subj = df_emails.iloc[x]['header']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_header'][x] = doc_subj.ents\n","\n","# body\n","  subj = df_emails.iloc[x]['body']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_body'][x] = doc_subj.ents"],"metadata":{"id":"EUPtluBAxq-2","executionInfo":{"status":"ok","timestamp":1658319758672,"user_tz":-120,"elapsed":99646,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["df_emails[['header','NER_header','NER_body']][0:40]"],"metadata":{"id":"yeWkiLUoxsEn","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1658319758678,"user_tz":-120,"elapsed":56,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"6550c8ec-351e-4f13-fff5-1c308cccd815"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               header              NER_header  \\\n","0                                                 NaN                      ()   \n","1                                                 Re:                      ()   \n","2                                            Re: test                      ()   \n","3                                                 NaN                      ()   \n","4                                           Re: Hello                      ()   \n","5                                           Re: Hello                      ()   \n","6                                                 NaN                      ()   \n","7                        Re: PRC review - phone calls                ((PRC),)   \n","8                      Re: High Speed Internet Access                      ()   \n","9   FW: fixed forward or other Collar floor gas pr...     ((FW, :), (Collar))   \n","10  Re: FW: fixed forward or other Collar floor ga...             ((Collar),)   \n","11                                                NaN                      ()   \n","12        Consolidated positions: Issues & To Do list  ((Issues, &, To, Do),)   \n","13        Consolidated positions: Issues & To Do list  ((Issues, &, To, Do),)   \n","14                                                NaN                      ()   \n","15                               Re: 2001 Margin Plan               ((2001),)   \n","16               Var, Reporting and Resources Meeting                ((Var),)   \n","17                                                NaN                      ()   \n","18                                           Westgate                      ()   \n","19         Meeting re: Storage Strategies in the West                      ()   \n","20                                                NaN                      ()   \n","21                         Re: Not business related..                      ()   \n","22                    Re: Original Sept check/closing                      ()   \n","23                                     San Juan Index          ((San, Juan),)   \n","24                                     San Juan Index          ((San, Juan),)   \n","25                               Investment Structure                      ()   \n","26                               Investment Structure                      ()   \n","27                                                NaN                      ()   \n","28                                                NaN                      ()   \n","29                     Re: Gas Trading Vision meeting                      ()   \n","30                                                NaN                      ()   \n","31                    Gas Physical/Financial Position                      ()   \n","32                                            closing                      ()   \n","33                                                NaN                      ()   \n","34                                                NaN                      ()   \n","35                                                NaN                      ()   \n","36                                                NaN                      ()   \n","37                                                NaN                      ()   \n","38                                                NaN                      ()   \n","39                                                NaN                      ()   \n","\n","                                             NER_body  \n","0                                                  ()  \n","1                                         ((Austin),)  \n","2                                                  ()  \n","3                               ((Randy), (Patti, S))  \n","4                                ((Tuesday), (11:45))  \n","5                       ((next, Tuesday), (Thursday))  \n","6   ((Phillip, Allen), (Mike, Grigsby), (Keith, Ho...  \n","7                              ((10, and, 11:30, '),)  \n","8                      ((ISP), (2), (IP), (DNS), (3))  \n","9   ((Phillip, K, Allen, /, HOU, /, ECT), (01:42, ...  \n","10  ((Buckner), (San, Diego), (Enron, Energy, Serv...  \n","11                           ((Lucy), (', 4), (', 5))  \n","12  ((Phillip, K, Allen, /, HOU, /, ECT), (02:16, ...  \n","13  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","14                                ((Dave), (Phillip))  \n","15                           ((Paula), (35, million))  \n","16  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...  \n","17                                           ((Tim),)  \n","18  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:3...  \n","19  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:1...  \n","20                    ((Brenda), (second), (October))  \n","21                                        ((Fletch),)  \n","22                    ((Brenda), (second), (October))  \n","23  ((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...  \n","24  ((yesterday), (El, Paso), (San, Juan), (monthl...  \n","25  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...  \n","26  ((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...  \n","27  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","28                            ((Reagan), (12), (FHA))  \n","29                                         ((Nymex),)  \n","30  ((Phillip, K, Allen, /, HOU, /, ECT), (Richard...  \n","31  ((Phillip, K, Allen, /, HOU, /, ECT), (12:07, ...  \n","32  ((Phillip, K, Allen, /, HOU, /, ECT), (11:57, ...  \n","33                           ((Chris), (PG&E), (EOL))  \n","34  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","35  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","36                                         ((Keith),)  \n","37  ((daily), (Mike, Grigsby), (37031), (today), (...  \n","38  ((Denver), (2002), (2003), (25,000), (2004), (...  \n","39      ((Jim), (weekly), (California), (this, week))  "],"text/html":["\n","  <div id=\"df-be34ebde-af5a-4a5e-a658-2aa8d4372917\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>header</th>\n","      <th>NER_header</th>\n","      <th>NER_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Re:</td>\n","      <td>()</td>\n","      <td>((Austin),)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Re: test</td>\n","      <td>()</td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Randy), (Patti, S))</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Re: Hello</td>\n","      <td>()</td>\n","      <td>((Tuesday), (11:45))</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Re: Hello</td>\n","      <td>()</td>\n","      <td>((next, Tuesday), (Thursday))</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, Allen), (Mike, Grigsby), (Keith, Ho...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Re: PRC review - phone calls</td>\n","      <td>((PRC),)</td>\n","      <td>((10, and, 11:30, '),)</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Re: High Speed Internet Access</td>\n","      <td>()</td>\n","      <td>((ISP), (2), (IP), (DNS), (3))</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>FW: fixed forward or other Collar floor gas pr...</td>\n","      <td>((FW, :), (Collar))</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (01:42, ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Re: FW: fixed forward or other Collar floor ga...</td>\n","      <td>((Collar),)</td>\n","      <td>((Buckner), (San, Diego), (Enron, Energy, Serv...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Lucy), (', 4), (', 5))</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Consolidated positions: Issues &amp; To Do list</td>\n","      <td>((Issues, &amp;, To, Do),)</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (02:16, ...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Consolidated positions: Issues &amp; To Do list</td>\n","      <td>((Issues, &amp;, To, Do),)</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Dave), (Phillip))</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Re: 2001 Margin Plan</td>\n","      <td>((2001),)</td>\n","      <td>((Paula), (35, million))</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Var, Reporting and Resources Meeting</td>\n","      <td>((Var),)</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Tim),)</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Westgate</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:3...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Meeting re: Storage Strategies in the West</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:1...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Re: Not business related..</td>\n","      <td>()</td>\n","      <td>((Fletch),)</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Re: Original Sept check/closing</td>\n","      <td>()</td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>San Juan Index</td>\n","      <td>((San, Juan),)</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>San Juan Index</td>\n","      <td>((San, Juan),)</td>\n","      <td>((yesterday), (El, Paso), (San, Juan), (monthl...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Investment Structure</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Investment Structure</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Reagan), (12), (FHA))</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Re: Gas Trading Vision meeting</td>\n","      <td>()</td>\n","      <td>((Nymex),)</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (Richard...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Gas Physical/Financial Position</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (12:07, ...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>closing</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (11:57, ...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Chris), (PG&amp;E), (EOL))</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Keith),)</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((daily), (Mike, Grigsby), (37031), (today), (...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Denver), (2002), (2003), (25,000), (2004), (...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>NaN</td>\n","      <td>()</td>\n","      <td>((Jim), (weekly), (California), (this, week))</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be34ebde-af5a-4a5e-a658-2aa8d4372917')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-be34ebde-af5a-4a5e-a658-2aa8d4372917 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-be34ebde-af5a-4a5e-a658-2aa8d4372917');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["id = 12\n","doc= nlp(df_emails['header'][id])\n","displacy.render(doc, style = \"ent\",jupyter = True)\n","print(\"----- eMail \",id,\" -----\")\n","doc= nlp(df_emails['body'][id])\n","displacy.render(doc, style = \"ent\",jupyter = True)\n","print(\"\\n\")"],"metadata":{"id":"qCT8gU8ox2A4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1658319758679,"user_tz":-120,"elapsed":44,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"6b49cc21-4f3e-4678-8bb9-ad42aca44c7d"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Consolidated positions: \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Issues &amp; To Do\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," list</div></span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----- eMail  12  -----\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">['', '---------------------- Forwarded by \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Phillip K Allen/HOU/ECT\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," on 10/09/2000 ', '\n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    02:16 PM\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n","</mark>\n"," ---------------------------', '', '', '\n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Richard Burchfield'\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", '10/06/2000 06:59 AM', 'To: \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Phillip K Allen/HOU/ECT@ECT'\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", 'cc: \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Beth Perlman/HOU/ECT@ECT '\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", 'Subject: Consolidated positions: \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Issues &amp; To Do\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," list', '', 'Phillip,', ' Below is the issues &amp; to do list as we go forward with documenting the ', 'requirements for consolidated physical/financial positions and transport ', &quot;trade capture. What we need to focus on is the \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    first\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n","</mark>\n"," bullet in \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Allan\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n","'s list; &quot;, 'the need for a single set of requirements. Although the meeting with \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Keith\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", ', 'on \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Wednesday\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n",",  was informative the solution of creating a infinitely dynamic ', 'consolidated position screen, will be extremely difficult and time ', 'consuming.  Throughout the meeting on \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Wednesday\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n",", \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Keith\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," alluded to the ', 'inability to get consensus amongst the traders on the presentation of the ', 'consolidated position, so the solution was to make it so that a trader can ', 'arrange the position screen to their liking (much like \n","<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Excel\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n","</mark>\n","). What needs to ', 'happen on \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Monday\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," from \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    3 - 5\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," is a effort to design a desired layout for the ', 'consolidated position screen, this is critical. This does not exclude ', 'building a capability to create a more flexible position presentation for the ', 'future, but in order to create a plan that can be measured we need firm ', 'requirements. Also, to reiterate that the goals of this project is a project ', 'plan on consolidate physical/financial positions and transport trade capture. ', 'The other issues that have been raised will be capture as projects on to ', 'themselves, and will need to be prioritised as efforts outside of this ', 'project.', '', 'I have been involved in most of the meetings and the discussions have been ', 'good. I believe there has been good communication between the teams, but now ', 'we need to have focus on the objectives we set out to solve.', '', '\n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Richard  '\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", '---------------------- Forwarded by \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Richard Burchfield\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n","/HOU/ECT on 10/06/2000 ', '08:34 AM ---------------------------', '', '', '\n","<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Allan Severude'\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n","</mark>\n",", '10/05/2000 \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    06:03 PM'\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n","</mark>\n",", 'To: \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Richard Burchfield/HOU/ECT@ECT'\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", 'cc: \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Peggy Alix/HOU/ECT@ECT\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",", \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Russ Severson/HOU/ECT@ECT\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Scott\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," ', '\n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Mills/HOU/ECT@ECT\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",", \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Kenny Ha/HOU/ECT@ECT '\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", 'Subject: Consolidated positions: \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Issues &amp; To Do\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," list', '', '', 'From our initial set of meetings with the traders regarding consolidated ', 'positions, I think we still have the following issues:', &quot;We don't have a single point of contact from the trading group.  We've had &quot;, '\n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    three\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," meetings which brought out very different issues from different ', 'traders.  We really need a single point of contact to help drive the trader ', 'requirements and help come to a consensus regarding the requirements.', &quot;We're getting hit with a lot of different requests, many of which appear to &quot;, 'be outside the scope of position consolidation.', '', 'Things left to do:', 'I think it may be useful to try to formulate a high level project goal to ', &quot;make it as clear as possible what we're trying to accomplish with this &quot;, &quot;project.  It'll help determine which requests fall under the project scope.&quot;, 'Go through the list of requests to determine which are in scope for this ', 'project and which fall out of scope.', 'For those in scope, work to define relative importance (priority) of each and ', 'work with traders to define the exact requirements of each.', 'Define the desired lay out of the position manager screen: main view and all ', 'drill downs.', 'Use the above to formulate a project plan.', '', 'Things requested thus far (no particular order):', 'Inclusion of Sitara physical deals into the \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," position manager and deal ', 'ticker.', 'Customized rows and columns in the position manager (ad hoc rows/columns that ', 'add up existing position manager rows/columns).', 'New drill down in the position manager to break out positions by: physical, ', 'transport, swaps, options, ...', 'Addition of a curve tab to the position manager to show the real-time values ', 'of all curves on which the desk has a position.', 'Ability to split the current position grid to allow \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    daily\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," positions to be ', 'shown directly above \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    monthly\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," positions.  Each grouped column in the top grid ', 'would be tied to a grouped column in the bottom grid.', 'Ability to properly show curve shift for float-for-float deals; determine the ', 'appropriate positions to show for each:', 'Gas Daily for \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    monthly\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," index,', 'Physical gas for \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Nymex\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",",', 'Physical gas for \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Inside Ferc\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",",', 'Physical gas for Mid market.', 'Ability for \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," to pull valuation results based on a \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," flag instead of ', 'using official valuations.', 'Position and \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    P&amp;L\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," aggregation across all gas desks.', 'Ability to include the Gas Price book into \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",":', 'Inclusion of spread options in our systems.  Ability to handle volatility ', 'skew and correlations.', 'Ability to revalue all options incrementally throughout the trading day.  ', 'Approximate delta changes between valuations using instantaneous gamma or a ', 'gamma grid.', 'Valuation of Gas Daily options.', 'A new position screen for options (\n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    months\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," x strike x delta).  TBD.', 'Inclusion of positions for exotic options currently managed in spreadsheets.', 'Ability to isolate the position change due to changed deals in the position ', 'manager.', 'Ability to view change deal \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    P&amp;L\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," in the \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," deal ticker.  Show new deal terms, ', 'prior deal terms, and net \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    P&amp;L\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," affect of the change.', 'Eliminate change deals with no economic impact from the \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," deal ticker.', 'Position drill down in the position manager to isolate the impact of ', 'individual deals on the position total in a grid cell.', 'Benchmark positions in \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    TDS\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n",".', 'Deployment of TDS in \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Canada\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n",". Currency and volume uom conversions. Implicit ', 'and explicit position break out issues.', '', '-- Allan.', '', 'PS: \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Colleen\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," is setting up a meeting \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    tomorrow\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," to discuss the direction for ', &quot;transport.  Hopefully we'll know much better where that part stands at that &quot;, 'point.', '', '', '', '', '']</div></span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n"]}]},{"cell_type":"code","source":["df_emails[['header','body','body_dict','summary_TFIDF','NER_body']][0:30]"],"metadata":{"id":"wu1GiVXLx-JE","colab":{"base_uri":"https://localhost:8080/","height":989},"executionInfo":{"status":"ok","timestamp":1658319758680,"user_tz":-120,"elapsed":43,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"4e7537c8-c360-4515-bc63-64dd5004c0cb"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               header  \\\n","0                                                 NaN   \n","1                                                 Re:   \n","2                                            Re: test   \n","3                                                 NaN   \n","4                                           Re: Hello   \n","5                                           Re: Hello   \n","6                                                 NaN   \n","7                        Re: PRC review - phone calls   \n","8                      Re: High Speed Internet Access   \n","9   FW: fixed forward or other Collar floor gas pr...   \n","10  Re: FW: fixed forward or other Collar floor ga...   \n","11                                                NaN   \n","12        Consolidated positions: Issues & To Do list   \n","13        Consolidated positions: Issues & To Do list   \n","14                                                NaN   \n","15                               Re: 2001 Margin Plan   \n","16               Var, Reporting and Resources Meeting   \n","17                                                NaN   \n","18                                           Westgate   \n","19         Meeting re: Storage Strategies in the West   \n","20                                                NaN   \n","21                         Re: Not business related..   \n","22                    Re: Original Sept check/closing   \n","23                                     San Juan Index   \n","24                                     San Juan Index   \n","25                               Investment Structure   \n","26                               Investment Structure   \n","27                                                NaN   \n","28                                                NaN   \n","29                     Re: Gas Trading Vision meeting   \n","\n","                                                 body body_dict summary_TFIDF  \\\n","0               ['', 'Here is our forecast', '', ' ']                           \n","1   ['', 'Traveling to have a business meeting tak...                           \n","2              ['', 'test successful.  way to go!!!']                           \n","3   ['', 'Randy,', '', ' Can you send me a schedul...                           \n","4         ['', \"Let's shoot for Tuesday at 11:45.  \"]                           \n","5   ['', 'Greg,', '', ' How about either next Tues...                           \n","6   ['', 'Please cc the following distribution lis...                           \n","7            ['', 'any morning between 10 and 11:30']                           \n","8   ['', '1. login:  pallen pw: ke9davis', '', \" I...                           \n","9   ['', '---------------------- Forwarded by Phil...                           \n","10  ['', 'Mr. Buckner,', '', ' For delivered gas b...                           \n","11  ['', 'Lucy,', '', ' Here are the rentrolls:', ...                           \n","12  ['', '---------------------- Forwarded by Phil...                           \n","13  ['', '---------------------- Forwarded by Phil...                           \n","14  ['', 'Dave, ', '', ' Here are the names of the...                           \n","15  ['', 'Paula,', '', ' 35 million is fine', '', ...                           \n","16  ['', '---------------------- Forwarded by Phil...                           \n","17  ['', 'Tim,', '', 'mike grigsby is having probl...                           \n","18  ['', '---------------------- Forwarded by Phil...                           \n","19  ['', '---------------------- Forwarded by Phil...                           \n","20  ['', 'Brenda,', '', 'Please use the second che...                           \n","21  ['', 'I think Fletch has a good CPA.  I am sti...                           \n","22  ['', 'Brenda,', '', ' Please use the second ch...                           \n","23  ['', '---------------------- Forwarded by Phil...                           \n","24  ['', 'Liane,', '', ' As we discussed yesterday...                           \n","25  ['', '---------------------- Forwarded by Phil...                           \n","26  ['', '---------------------- Forwarded by Phil...                           \n","27  ['', '---------------------- Forwarded by Phil...                           \n","28  ['', 'Reagan,', '', 'Just wanted to give you a...                           \n","29  ['', 'Nymex expiration is during this time fra...                           \n","\n","                                             NER_body  \n","0                                                  ()  \n","1                                         ((Austin),)  \n","2                                                  ()  \n","3                               ((Randy), (Patti, S))  \n","4                                ((Tuesday), (11:45))  \n","5                       ((next, Tuesday), (Thursday))  \n","6   ((Phillip, Allen), (Mike, Grigsby), (Keith, Ho...  \n","7                              ((10, and, 11:30, '),)  \n","8                      ((ISP), (2), (IP), (DNS), (3))  \n","9   ((Phillip, K, Allen, /, HOU, /, ECT), (01:42, ...  \n","10  ((Buckner), (San, Diego), (Enron, Energy, Serv...  \n","11                           ((Lucy), (', 4), (', 5))  \n","12  ((Phillip, K, Allen, /, HOU, /, ECT), (02:16, ...  \n","13  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","14                                ((Dave), (Phillip))  \n","15                           ((Paula), (35, million))  \n","16  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...  \n","17                                           ((Tim),)  \n","18  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:3...  \n","19  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:1...  \n","20                    ((Brenda), (second), (October))  \n","21                                        ((Fletch),)  \n","22                    ((Brenda), (second), (October))  \n","23  ((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...  \n","24  ((yesterday), (El, Paso), (San, Juan), (monthl...  \n","25  ((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...  \n","26  ((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...  \n","27  ((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...  \n","28                            ((Reagan), (12), (FHA))  \n","29                                         ((Nymex),)  "],"text/html":["\n","  <div id=\"df-1b2c2404-0f87-491a-9c03-822435ebed99\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>header</th>\n","      <th>body</th>\n","      <th>body_dict</th>\n","      <th>summary_TFIDF</th>\n","      <th>NER_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>['', 'Here is our forecast', '', ' ']</td>\n","      <td></td>\n","      <td></td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Re:</td>\n","      <td>['', 'Traveling to have a business meeting tak...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Austin),)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Re: test</td>\n","      <td>['', 'test successful.  way to go!!!']</td>\n","      <td></td>\n","      <td></td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>['', 'Randy,', '', ' Can you send me a schedul...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Randy), (Patti, S))</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Re: Hello</td>\n","      <td>['', \"Let's shoot for Tuesday at 11:45.  \"]</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Tuesday), (11:45))</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Re: Hello</td>\n","      <td>['', 'Greg,', '', ' How about either next Tues...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((next, Tuesday), (Thursday))</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>['', 'Please cc the following distribution lis...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, Allen), (Mike, Grigsby), (Keith, Ho...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Re: PRC review - phone calls</td>\n","      <td>['', 'any morning between 10 and 11:30']</td>\n","      <td></td>\n","      <td></td>\n","      <td>((10, and, 11:30, '),)</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Re: High Speed Internet Access</td>\n","      <td>['', '1. login:  pallen pw: ke9davis', '', \" I...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((ISP), (2), (IP), (DNS), (3))</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>FW: fixed forward or other Collar floor gas pr...</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (01:42, ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Re: FW: fixed forward or other Collar floor ga...</td>\n","      <td>['', 'Mr. Buckner,', '', ' For delivered gas b...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Buckner), (San, Diego), (Enron, Energy, Serv...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>NaN</td>\n","      <td>['', 'Lucy,', '', ' Here are the rentrolls:', ...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Lucy), (', 4), (', 5))</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Consolidated positions: Issues &amp; To Do list</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (02:16, ...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Consolidated positions: Issues &amp; To Do list</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>NaN</td>\n","      <td>['', 'Dave, ', '', ' Here are the names of the...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Dave), (Phillip))</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Re: 2001 Margin Plan</td>\n","      <td>['', 'Paula,', '', ' 35 million is fine', '', ...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Paula), (35, million))</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Var, Reporting and Resources Meeting</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>NaN</td>\n","      <td>['', 'Tim,', '', 'mike grigsby is having probl...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Tim),)</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Westgate</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:3...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Meeting re: Storage Strategies in the West</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:1...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>NaN</td>\n","      <td>['', 'Brenda,', '', 'Please use the second che...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Re: Not business related..</td>\n","      <td>['', 'I think Fletch has a good CPA.  I am sti...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Fletch),)</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Re: Original Sept check/closing</td>\n","      <td>['', 'Brenda,', '', ' Please use the second ch...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Brenda), (second), (October))</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>San Juan Index</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (01:09, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>San Juan Index</td>\n","      <td>['', 'Liane,', '', ' As we discussed yesterday...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((yesterday), (El, Paso), (San, Juan), (monthl...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Investment Structure</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 04:2...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Investment Structure</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (04:26, ...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>NaN</td>\n","      <td>['', '---------------------- Forwarded by Phil...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Phillip, K, Allen, /, HOU, /, ECT), (', 02:0...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>NaN</td>\n","      <td>['', 'Reagan,', '', 'Just wanted to give you a...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Reagan), (12), (FHA))</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Re: Gas Trading Vision meeting</td>\n","      <td>['', 'Nymex expiration is during this time fra...</td>\n","      <td></td>\n","      <td></td>\n","      <td>((Nymex),)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b2c2404-0f87-491a-9c03-822435ebed99')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1b2c2404-0f87-491a-9c03-822435ebed99 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1b2c2404-0f87-491a-9c03-822435ebed99');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["# import spacy\n","# from spacy import displacy\n","# nlp = spacy.load('en_core_web_sm')\n","# spacy_stopwords = nlp.Defaults.stop_words\n","# stopwords = spacy_stopwords\n","# print(spacy_stopwords)"],"metadata":{"id":"sHTuVMN4iZaQ","executionInfo":{"status":"ok","timestamp":1658319758681,"user_tz":-120,"elapsed":42,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["# Data cleaning"],"metadata":{"id":"xIUXYLne_Hh8"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","import re\n","\n","def data_clean (tokens):\n","# Suppression des caractères spéciaux ou inutiles \\“‘,]\n","#  print(“Data cleaning --\\n”)\n","#  print(“Avant :\\n”,type(tokens),” “,tokens)\n","   r = re.compile(r\"[\\\\\\''\\'\\\"\\[\\]]+\")\n","   tok=r.sub('', tokens)\n","   r = re.compile(r\"([\\(\\)]{1,}|,{2,})\")\n","   tok2=r.sub(' ', tok)\n","   r = re.compile(r\"((\\.\\s?,)+|(, ,)|(^,{1,}))\")\n","   tok3=r.sub('', tok2)\n","   r = re.compile(r\"\\s{2,}\")\n","   texte=r.sub(' ', tok3)\n","#  texte = sent_tokenize(texte)  # découpe en phrases stockées dans une liste\n","#  print(“Après sent_tokenize :\\n”,type(texte),” “,texte)\n","   return texte"],"metadata":{"id":"J3AM6gXAjKn2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_stop_words(text,stopwords):\n","  lst=[]\n","#  for token in str(text).split():\n","  for token in text.split():\n","    if token.lower() not in stopwords:    #checking whether the word is not \n","      lst.append(token)                    #present in the stopword list.      \n","#    else:\n","#      print(\"suppression du stopword : \",token)\n","  # Join items in the list\n","#   print(\"Original text before removing stopwords  :   \\n\",text)\n","  result = ' '.join(lst)\n","#   print(\"Text after removing stopwords  :   \\n\",result)\n","  return result"],"metadata":{"id":"S_I3qqRIt79M","executionInfo":{"status":"ok","timestamp":1658319758682,"user_tz":-120,"elapsed":36,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Transforme Text en Dictionnaire - Key = indice de phrase - Value = Mots de la phrase\n","import re\n","from nltk.tokenize import sent_tokenize,word_tokenize\n","\n","def dictionarize(article):\n","    dico={}\n","    phrases=sent_tokenize(article)\n","    phr2=[]\n","    for i, phr in enumerate(phrases):\n","        import re\n","        phr=re.sub(pattern =\"[^a-zA-Z]\", repl = ' ', string = phr)\n","        phr2.append(phr)\n","    \n","        phr=word_tokenize(phr)\n","        phr_lower=[w.lower() for w in phr]\n","        if len(phr_lower)>4:      \n","            dico[i]=phr_lower    \n","    return dico\n","\n"],"metadata":{"id":"v7Enu2jNVjHU","executionInfo":{"status":"ok","timestamp":1658319758683,"user_tz":-120,"elapsed":36,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["df_emails.shape[0]"],"metadata":{"id":"YdwAE_vc_o5o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658319758684,"user_tz":-120,"elapsed":36,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"923bab71-947b-4050-86aa-598b40cc2b1b"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["# Summary methodS"],"metadata":{"id":"sZdYBjoCotLn"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","\n","def TF(token, artikle):\n","    \"\"\"\n","    Calcule le score TF d'un mot dans un artikle\n","    \n","    token : Mot dont le score TF doit être calculé.\n","    \n","    artikle : Dictionnaire généré à partir d'un texte.\n","    \"\"\"\n","    f = 0\n","    for key in artikle:\n","        for work in artikle[key]:\n","            if work == token:\n","                f += 1 \n","    return np.log(f+1)\n","\n","def IDF(token, corpus):\n","    \"\"\"\n","    Calcule le score IDF d'un mot dans un corpus d'artikles.\n","    \n","    token : Mot dont le score IDF doit être calculé.\n","    \n","    corpus : Liste d'artikles.\n","    \"\"\"\n","    N = len(corpus)\n","    d=0\n","    present = False\n","    \n","    for artikle in corpus:\n","        for key in artikle:\n","            if token in artikle[key]:\n","                present = True\n","        d += int(present)\n","        present = False\n","                \n","    return np.log(N/(d+1) +1)\n","\n","def TFIDF(token, artikle, corpus):\n","    \"\"\"\n","    Calcule le score TF-IDF d'un mot dans un texte.\n","    \n","    token : mot dont le score doit être calculé.\n","    \n","    artikle : artikle qui servira à calculer le score du mot dans cet artikle.\n","    \n","    corpus : Liste d'artikles formant le corpus.\n","    \"\"\"\n","    return TF(token, artikle)*IDF(token, corpus)\n","\n","def score_sentence(corpus, artikle, sentence):\n","    \"\"\"\n","    Calcule le score d'une phrase.\n","    \n","    corpus : Liste d'artikles.\n","    \n","    artikle : Dictionnaire de phrases.\n","    \n","    sentence : Phrase sous forme de liste de mots.\n","    \"\"\"\n","    score_sentence = []\n","    for word in sentence :\n","        score_word = TFIDF(word, artikle, corpus)\n","        score_sentence.append(score_word)\n","    return np.mean(score_sentence)\n","\n","def best_sentences(scores_artikle, nb_sentences):\n","    \"\"\"\n","    Retourne les indices des phrases les plus importantes en fonction des scores obtenus.\n","    \n","    scores_artikle : Liste des scores de chaque phrase dans un texte.\n","    \n","    nb_sentences : Nombre de phrases à sélectionner.\n","    \"\"\"\n","    \n","    return sorted(np.argsort(scores_artikle)[-nb_sentences:])\n","\n","def summarize_TFIDF(i, n_sentences, df):\n","    \"\"\"\n","    Synthèse extractive d'un article par la méthode TF-IDF.\n","    \n","    i : indice de l'article dans le corpus.\n","    \n","    n_sentences : nombre de phrases à conserver.\n","    \n","    df : DataFrame contenant les artikles dans une colonne 'Artikle'.    \n","    \"\"\"\n","    corpus = df['body_dict']\n","    artikle = corpus[i]\n","    texte=df['body'][i]\n","    \n","    if len(corpus) <= n_sentences:\n","      print(\"Longeur corpus inférieure au nombre minimal de phrases retenu pour le résumé\")\n","      return texte\n","    # Calcul du score de chaque phrase de l'artikle\n","    scores_artikle = [score_sentence(corpus, artikle, sentence) for sentence in artikle.values()]\n"," \n","    \n","    # Extraction des indices des phrases ayant les meilleurs scores\n","    result = best_sentences(scores_artikle, n_sentences)\n","#    print('best sentences :',result)\n","    \n","    # Séparation de phrases l'article original \n","    tokenized_article = sent_tokenize(texte)\n","    \n","    # Extraction des phrases les plus importantes\n","    summary = [tokenized_article[i] for i in result]\n","#    print(\"[\",i,\"] :\",summary)\n","    # transformation finale en chaine de caracteres\n","    texte = ''.join(summary)\n","    return texte\n","\n","def summarize_spacy (text,ratio):\n","  # https://www.numpyninja.com/post/text-summarization-through-use-of-spacy-library\n","  nlp = spacy.load('en_core_web_sm')\n","  doc= nlp(text)\n","  tokens=[token.text for token in doc]\n","#  print(\"Tokens : \\n\",tokens)\n","\n","  # calcul frequence de mots\n","  word_frequencies={}\n","  for word in doc:\n","    if word.text.lower() not in stopwords:\n","      if word.text.lower() not in punctuation:\n","        if word.text not in word_frequencies.keys():\n","          word_frequencies[word.text] = 1\n","        else:\n","          word_frequencies[word.text] += 1\n","#  print(\"\\n word_frequencies : \",word_frequencies)\n","\n","  # normalisation des frequence de mots\n","  max_frequency=max(word_frequencies.values())\n","  for word in word_frequencies.keys():\n","    word_frequencies[word]=word_frequencies[word]/max_frequency\n","#  print(\"\\n Normalized word_frequencies : \\n\",word_frequencies)\n","  # Sentences token\n","  sentence_tokens= [sent for sent in doc.sents]\n","#  print(sentence_tokens)\n","  # Calculate the most important sentences by adding the word frequencies in each sentence.\n","  sentence_scores = {}\n","  for sent in sentence_tokens:\n","    for word in sent:\n","      if word.text.lower() in word_frequencies.keys():\n","        if sent not in sentence_scores.keys():                            \n","          sentence_scores[sent]=word_frequencies[word.text.lower()]\n","        else:\n","          sentence_scores[sent]+=word_frequencies[word.text.lower()]\n","\n","  # identifier % (ratio) du texte avec score maximum\n","  from heapq import nlargest\n","  select_length=int(len(sentence_tokens)*ratio)\n","  select_length\n","  summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n","  final_summary=[word.text for word in summary]\n","  summary=''.join(final_summary)\n","  return summary\n","\n"],"metadata":{"id":"E_flKIgS5ra2","executionInfo":{"status":"ok","timestamp":1658319758685,"user_tz":-120,"elapsed":34,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4q-wvLbowfP","executionInfo":{"status":"ok","timestamp":1658319758686,"user_tz":-120,"elapsed":34,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"784c7bb0-bce7-4f25-8b77-0eabb2499bc5"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}]},{"cell_type":"code","source":["def summarize_abstractive (text, min_length, max_length):\n","  print(\"paramètres :\", min_length, max_length)\n","  print(\"texte : \",len(text),text)\n","  from transformers import pipeline\n","#  print(\"Avant : \",text)\n","  # use the BART model, which is trained on the CNN/Daily Mail News Dataset, you can directly use the default parameters\n","  # bart-large-cnn model for summarization\n","  summarizer = pipeline(\"summarization\")\n","  summarized = summarizer(text, min_length, max_length)\n","  summary=' '.join([str(i) for i in summarized])\n","#  print(\"Après : \",summary)\n","  return summary\n","\n","from transformers import pipeline\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","#def summarize_T5 (text, min_length, max_length):\n","def summarize_T5 (text):\n","  summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n","  summary_text = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\n","  return summary_text\n","  "],"metadata":{"id":"mkunOJ0Gefoc","executionInfo":{"status":"ok","timestamp":1658319758686,"user_tz":-120,"elapsed":27,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["# Test Unitaire"],"metadata":{"id":"YWdHHy9jD-Vv"}},{"cell_type":"code","source":["id = 44\n","df_emails['body_clean'][id] = data_clean(df_emails['body'].iloc[id])\n","\n","text = df_emails['body_clean'][id]\n","print(\"Original text : \")\n","print(df_emails['body'][id])\n","print(\"\\nCleaned text : \",type(text),len(text),\" car. : \")\n","print(text,\"\\n\")\n","# Extractive summary using TF-IDF\n","# ------------------------------------------------------------------------\n","# suppression de stopwords pour TFIDF\n","text = remove_stop_words(text,stopwords)\n","\n","# Dictionnarize the text to be used with TF-IDF\n","print(\"Extractive summary using TF-IDF\")\n","max_sent = 3\n","df_emails['body_dict'][id] = dictionarize(text)   # sans stopwords\n","if len(df_emails['body_dict'][id]) > max_sent:\n","  text = df_emails['body_dict'][id]\n","  # on affiche phrase par phrase le contenu de chaque mail\n","  for cle, valeur in text.items():\n","    print(\"Ligne \", cle, \" : \", valeur)\n","  # Identification des max_sent les plus significatives \n","  df_emails['summary_TFIDF'][id] = summarize_TFIDF(id, max_sent, df_emails)\n","  ratio = len(df_emails['summary_TFIDF'][id])/len(df_emails['body_clean'][id])\n","  print(\"\\nRésumé TFIDF - Len \",len(df_emails['summary_TFIDF'][id]),\" Ratio : \",int(ratio*100),\"%\")\n","  print(df_emails['summary_TFIDF'][id])\n","else:\n","  print(\"ID \",id,\" contenu trop court. Reprise de l'original pour TFIDF\")\n","  df_emails['summary_TFIDF'][id] = df_emails['body_clean'][id]\n","\n","# ------------------------------------------------------------------------\n","# Extractive summary using Spacy\n","print(\"\\nExtractive summary using Spacy\")\n","ratio = 0.30\n","text = df_emails['body_clean'].iloc[id]\n","df_emails['summary_spacy'][id] = summarize_spacy (str(text),ratio)\n","ratio = len(df_emails['summary_spacy'][id])/len(df_emails['body_clean'][id])\n","print(\"Résumé Spacy - Len \",len(df_emails['summary_spacy'][id]),\"Ratio : \",int(ratio*100),\"%\")\n","print(df_emails['summary_spacy'][id])\n","\n","# ------------------------------------------------------------------------\n","# Extractive summary using Transformers\n","# BART model\n","print(\"\\nExtractive summary using Transformers / BART\")\n","text = df_emails['body_clean'].iloc[id]\n","try:\n","  df_emails['summary_abstractive'][id] = summarize_abstractive (text, min_length=30, max_length=100)\n","  ratio = len(df_emails['summary_abstractive'][id])/len(df_emails['body_clean'][id])\n","  print(\"\\nRésumé Transformers BART  - Len \",len(df_emails['summary_abstractive'][id]),\" Ratio : \",int(ratio*100),\"%\")\n","  print(df_emails['summary_abstractive'][id])\n","except:\n","  print(\"Pb extractive summary on Id \",id)\n","  df_emails['summary_abstractive'][id] = \"Erreur\"\n","\n","# # T5 model\n","\n"],"metadata":{"id":"vRnFPlS760S1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658321492906,"user_tz":-120,"elapsed":27433,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"836cce98-8a9c-4fa1-adb8-2a27e7a4792d"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text : \n","['', 'Jeff,', '', ' I need to see the site plan for Burnet.  Remember I must get written ', 'approval from Brenda Key Stone before I can sell this property and she has ', 'concerns about the way the property will be subdivided.    I would also like ', 'to review the closing statements as soon as possible.', '', 'Phillip']\n","\n","Cleaned text :  <class 'str'> 293  car. : \n"," Jeff , I need to see the site plan for Burnet. Remember I must get written , approval from Brenda Key Stone before I can sell this property and she has , concerns about the way the property will be subdivided. I would also like , to review the closing statements as soon as possible , Phillip \n","\n","Extractive summary using TF-IDF\n","ID  44  contenu trop court. Reprise de l'original pour TFIDF\n","\n","Extractive summary using Spacy\n"]},{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"]},{"output_type":"stream","name":"stdout","text":["Résumé Spacy - Len  0 Ratio :  0 %\n","\n","\n","Extractive summary using Transformers / BART\n","paramètres : 30 100\n","texte :  293  Jeff , I need to see the site plan for Burnet. Remember I must get written , approval from Brenda Key Stone before I can sell this property and she has , concerns about the way the property will be subdivided. I would also like , to review the closing statements as soon as possible , Phillip\n"]},{"output_type":"stream","name":"stderr","text":["Ignoring args : (30, 100)\n","Your max_length is set to 142, but you input_length is only 64. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Résumé Transformers BART  - Len  300  Ratio :  102 %\n","{'summary_text': ' Jeff , I need to see the site plan for Burnet. Remember I must get written approval from Brenda Key Stone before I can sell this property . Brenda has concerns about the way the property will be subdivided. I would also like to review the closing statements as soon as possible .'}\n"]}]},{"cell_type":"code","source":["df_emails['T5'] = ''"],"metadata":{"id":"y-k7_5jgpFwf","executionInfo":{"status":"ok","timestamp":1658319803038,"user_tz":-120,"elapsed":19,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["print(\"\\nExtractive summary using Transformers / T5\")\n","text = df_emails['body_clean'].iloc[id]\n","text = \"\"\"One month after the United States began what has become a troubled rollout of a national COVID vaccination campaign, the effort is finally gathering real steam.\n","Close to a million doses -- over 951,000, to be more exact -- made their way into the arms of Americans in the past 24 hours, the U.S. Centers for Disease Control and Prevention reported Wednesday. That's the largest number of shots given in one day since the rollout began and a big jump from the previous day, when just under 340,000 doses were given, CBS News reported.\n","That number is likely to jump quickly after the federal government on Tuesday gave states the OK to vaccinate anyone over 65 and said it\"\"\"\n","print(text)\n","try:\n","  df_emails['summary_T5'][id] = summarize_T5 (text)\n","  ratio = len(df_emails['summary_T5'][id])/len(df_emails['body_clean'][id])\n","  print(\"\\nRésumé Transformers T5  - Len \",len(df_emails['summary_T5'][id]),\" Ratio : \",int(ratio*100),\"%\")\n","  print(df_emails['summary_T5'][id])\n","except:\n","  print(\"Pb extractive summary on Id \",id)\n","  df_emails['summary_T5'][id] = \"Erreur\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iyPLXivpsUrz","executionInfo":{"status":"error","timestamp":1658319905936,"user_tz":-120,"elapsed":102917,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"f0306f62-fbec-4371-9434-3dface8a28bf"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Extractive summary using Transformers / T5\n","One month after the United States began what has become a troubled rollout of a national COVID vaccination campaign, the effort is finally gathering real steam.\n","Close to a million doses -- over 951,000, to be more exact -- made their way into the arms of Americans in the past 24 hours, the U.S. Centers for Disease Control and Prevention reported Wednesday. That's the largest number of shots given in one day since the rollout began and a big jump from the previous day, when just under 340,000 doses were given, CBS News reported.\n","That number is likely to jump quickly after the federal government on Tuesday gave states the OK to vaccinate anyone over 65 and said it\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n","\n","All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Pb extractive summary on Id  44\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'summary_T5'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-b0e5022dc7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdf_emails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_T5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_T5\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_emails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_T5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_emails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'summary_T5'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'summary_T5'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-b0e5022dc7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pb extractive summary on Id \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mdf_emails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_T5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Erreur\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'summary_T5'"]}]},{"cell_type":"code","source":["text = df_emails['body_clean'].iloc[id]\n","text"],"metadata":{"id":"BqKRAqOW3IHn","executionInfo":{"status":"aborted","timestamp":1658319905920,"user_tz":-120,"elapsed":16,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text\n","summary_text = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']"],"metadata":{"id":"ngqAC8wlzVet","executionInfo":{"status":"aborted","timestamp":1658319905921,"user_tz":-120,"elapsed":16,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id=20\n","id, len(df_emails['body_clean'][id]),(df_emails['body_clean'][id])\n"],"metadata":{"id":"CHvNHvuLmqEn","executionInfo":{"status":"aborted","timestamp":1658319905922,"user_tz":-120,"elapsed":17,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id, (df_emails['body_dict'][id])"],"metadata":{"id":"GCYSuo42kvqY","executionInfo":{"status":"aborted","timestamp":1658319905923,"user_tz":-120,"elapsed":18,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id, len(df_emails['body_dict'][id])"],"metadata":{"id":"FHd_Wkybk0y-","executionInfo":{"status":"aborted","timestamp":1658319905923,"user_tz":-120,"elapsed":18,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id, df_emails['summary_TFIDF'][id]"],"metadata":{"id":"awwVGZinl9k5","executionInfo":{"status":"aborted","timestamp":1658319905924,"user_tz":-120,"elapsed":19,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Boucle de traitement"],"metadata":{"id":"-S8GlkF467dm"}},{"cell_type":"code","source":["deb = 0\n","fin = df_emails.shape[0]\n","print(\"Traitement en cours pour \",fin, \"records\")\n","fin = 100\n","for id in range(deb,fin):\n","  print(\"\\n id : \",id)\n","  print('--------------------')\n","  # coller quand OK pour les tests unitaires\n","  df_emails['body_clean'][id] = data_clean(str(df_emails['body'].iloc[id]))\n","  text = df_emails['body_clean'][id]\n","  print(\"Cleaned text : \",len(str(text)),\" car.\\n\")\n","  print(text)\n","  # Extractive summary using TF-IDF\n","  # ------------------------------------------------------------------------\n","  # suppression de stopwords pour TFIDF\n","  text = remove_stop_words(text,stopwords)\n","\n","  # Dictionnarize the text to be used with TF-IDF\n","  df_emails['body_dict'][id] = dictionarize(text)   # sans stopwords\n","  max_sent = 3 \n","  if len(df_emails['body_dict'][id]) > max_sent:\n","    text = df_emails['body_dict'][id]\n","    # on affiche phrase par phrase le contenu de chaque mail\n","    for cle, valeur in text.items():\n","      print(\"Ligne \", cle, \" : \", valeur)\n","    # Identification des n_sent les plus significatives\n","\n","    df_emails['summary_TFIDF'][id] = summarize_TFIDF(id, max_sent, df_emails)\n","    ratio = len(df_emails['summary_TFIDF'][id])/len(df_emails['body_clean'][id])\n","    print(\"\\nRésumé TFIDF - Len \",len(df_emails['summary_TFIDF'][id]),\" Ratio : \",int(ratio*100),\"%\")\n","    print(df_emails['summary_TFIDF'][id])\n","  else:\n","    print(\"ID \",id,\" contenu trop court. Reprise de l'original pour TFIDF\")\n","    df_emails['summary_TFIDF'][id] = df_emails['body_clean'][id]\n","\n","# ------------------------------------------------------------------------\n","  # Extractive summary using Spacy\n","  ratio = 0.20\n","  text = df_emails['body_clean'].iloc[id]\n","  df_emails['summary_spacy'][id] = summarize_spacy (str(text),ratio)\n","  ratio = len(df_emails['summary_spacy'][id])/len(df_emails['body_clean'][id])\n","  print(\"\\nRésumé Spacy - Len \",len(df_emails['summary_spacy'][id]),\"Ratio : \",int(ratio*100),\"%\")\n","  print(df_emails['summary_spacy'][id])\n","\n","# ------------------------------------------------------------------------\n","# Extractive summary using Transformers\n","  try:\n","    text = df_emails['body_clean'].iloc[id]\n","    df_emails['summary_abstractive'][id] = summarize_abstractive (text, min_length=30, max_length=100)\n","    ratio = len(df_emails['summary_abstractive'][id])/len(df_emails['body_clean'][id])\n","    print(\"\\nRésumé Transformers BERT  - Len \",len(df_emails['summary_abstractive'][id]),\" Ratio : \",int(ratio*100),\"%\")\n","    print(df_emails['summary_abstractive'][id])\n","  except:\n","    print(\"Pb extractive summary on Id \",id)\n","    df_emails['summary_abstractive'][id] = \"Erreur\"\n"],"metadata":{"id":"dQ8G9SzEFtFL","executionInfo":{"status":"aborted","timestamp":1658319905925,"user_tz":-120,"elapsed":20,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# doc1.similarity(doc2)\n","!python -m spacy download en_core_web_lg"],"metadata":{"id":"30kb1RS5ljbb","executionInfo":{"status":"aborted","timestamp":1658319905926,"user_tz":-120,"elapsed":21,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_emails.head(20)"],"metadata":{"id":"exks77HnWKzn","executionInfo":{"status":"aborted","timestamp":1658319905927,"user_tz":-120,"elapsed":22,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","nlp = spacy.load('en_core_web_lg')\n","id=11\n","doc1 = nlp(df_emails['body_clean'][id])\n","doc2 = nlp(df_emails['summary_spacy'][id])\n","\n","# Get the similarity of doc1 and doc2\n","similarity = doc1.similarity(doc2)\n","print(similarity)"],"metadata":{"id":"uggk3EWcMgLm","executionInfo":{"status":"aborted","timestamp":1658319905927,"user_tz":-120,"elapsed":22,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SPACY - Summary (Abstractive / Word Embedding)"],"metadata":{"id":"G6MOR_tiyuty"}},{"cell_type":"code","source":["#!pip install spacy-transformers"],"metadata":{"id":"lzIZzQCZzEIl","executionInfo":{"status":"aborted","timestamp":1658319905928,"user_tz":-120,"elapsed":22,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://spacy.io/usage/embeddings-transformers\n","# https://spacy.io/api/transformer\n","\n","\n"],"metadata":{"id":"oP8OqCbkzEWL","executionInfo":{"status":"aborted","timestamp":1658319905929,"user_tz":-120,"elapsed":23,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://manusidtech.com/index.php/2021/08/14/complete-nlp-web-app-using-spacy-and-hugging-face-transformers/\n","#!pip install datasets transformers[sentencepiece]\n","#text = str(df_emails['body'][32])\n","#text=\"\"\"The human coronavirus was first diagnosed in 1965 by Tyrrell and Bynoe from the respiratory tract sample of an adult with a common cold cultured on human embryonic trachea.1 Naming the virus is based on its crown-like appearance on its surface.2 Coronaviruses (CoVs) are a large family of viruses belonging to the Nidovirales order, which includes Coronaviridae, Arteriviridae, and Roniviridae families.3 Coronavirus contains an RNA genome and belongs to the Coronaviridae family.4 This virus is further subdivided into four groups, ie, the α, β, γ, and δ coronaviruses.5 α- and β-coronavirus can infect mammals, while γ- and δ- coronavirus tend to infect birds.6 Coronavirus in humans causes a range of disorders, from mild respiratory tract infections, such as the common cold to lethal infections, such as the severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS) and Coronavirus disease 2019 (COVID-19). The coronavirus first appeared in the form of severe acute respiratory syndrome coronavirus (SARS-CoV) in Guangdong province, China, in 20027 followed by Middle East respiratory syndrome coronavirus (MERS-CoV) isolated from the sputum of a 60-year-old man who presented symptoms of acute pneumonia and subsequent renal failure in Saudi Arabia in 2012.8 In December 2019, a β-coronavirus was discovered in Wuhan, China. The World Health Organization (WHO) has named the new disease as Coronavirus disease 2019 (COVID-19), and Coronavirus Study Group (CSG) of the International Committee has named it as SARS-CoV-2.9,10 Based on the results of sequencing and evolutionary analysis of the viral genome, bats appear to be responsible for transmitting the virus to humans\"\"\"\n","#print(text)\n","\n","#print(summarize_abstractive (text))\n","#print(summarize_spacy (text))\n","#print()"],"metadata":{"id":"7Zzdcajk9iFi","executionInfo":{"status":"aborted","timestamp":1658319905931,"user_tz":-120,"elapsed":25,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A voir"],"metadata":{"id":"NiR7gR20Jioc"}},{"cell_type":"code","source":["# https://www.machinelearningplus.com/nlp/text-summarization-approaches-nlp-example/\n","# https://towardsdatascience.com/abstractive-summarization-using-pytorch-f5063e67510\n","# https://www.analyticsvidhya.com/blog/2021/10/text-summarization-using-the-conventional-hugging-face-transformer-and-cosine-similarity/\n"],"metadata":{"id":"S4nzClf9GUpR","executionInfo":{"status":"aborted","timestamp":1658319905931,"user_tz":-120,"elapsed":25,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python -m spacy download en_core_web_lg"],"metadata":{"id":"QZkhkSMqy-o_","executionInfo":{"status":"aborted","timestamp":1658319905932,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Calcul similarités des résumés"],"metadata":{"id":"Pnw7brl8hAYM"}},{"cell_type":"code","source":["spacy.load('en_core_web_lg')"],"metadata":{"id":"svIQGPjYCd1u","executionInfo":{"status":"aborted","timestamp":1658319905932,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load('en_core_web_lg')"],"metadata":{"id":"Q0HCgyGWChIh","executionInfo":{"status":"aborted","timestamp":1658319905933,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deb = 1\n","fin = df_emails.shape[0]\n","#fin = 21\n","print(\"Traitement en cours pour \",fin, \"records\")\n","\n","for id in range(deb,fin):\n","  print(\"ID:\",id)\n","  # Calcul de similarité avec texte initial nettoyé\n","  doc1 = nlp(df_emails['body_clean'][id])\n","  max_sim = 0\n","  doc2 = nlp(df_emails['summary_TFIDF'][id])\n","  if doc2 != \"\":\n","    sim = doc1.similarity(doc2)\n","    df_emails['summary_TFIDF_sim'][id] = sim\n","    max_sim = sim\n","\n","  doc2 = nlp(df_emails['summary_spacy'][id])\n","  if doc2 != \"\":\n","    sim = doc1.similarity(doc2)\n","    df_emails['summary_spacy_sim'][id] = sim\n","    if sim > max_sim:\n","      max_sim = sim\n","\n","  doc2 = nlp(df_emails['summary_abstractive'][id])\n","  if doc2 != \"Erreur\":\n","    sim = doc1.similarity(doc2)\n","    df_emails['summary_abstractive_sim'][id] = sim\n","    if sim > max_sim:\n","      max_sim = sim\n","\n","  print(\"Meilleur score : \",max_sim)\n","  df_emails['best_sim'][id] = max_sim\n"],"metadata":{"id":"e1UFNmw7n42V","executionInfo":{"status":"aborted","timestamp":1658319905933,"user_tz":-120,"elapsed":25,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_emails\n"],"metadata":{"id":"gt42iNJ3hHyw","executionInfo":{"status":"aborted","timestamp":1658319905934,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sauvegarde du fichier final en .csv et .xls"],"metadata":{"id":"FKKBZI3CeVFR"}},{"cell_type":"code","source":["# SAUVEGARDE en csv du résultat.\n","fin = df_emails.shape[0]\n","fin = 200\n","file_name = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique_output.csv\"\n","df_emails[deb:fin].to_csv(file_name, encoding='utf-8', index=False)\n","file_name = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique_output.xls\"\n","df_emails[deb:fin].to_excel(file_name, encoding='utf-8', index=False)\n","\n"],"metadata":{"id":"Fv2PQS15eTqH","executionInfo":{"status":"aborted","timestamp":1658319905934,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to gsheet\n","import gspread\n","# from gspread_dataframe import get_as_dataframe, set_with_dataframe\n","# set_with_dataframe(worksheet, df_emails)\n","sh = gc.create(\"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/enron_unique_output\")"],"metadata":{"id":"TlDIoibohi92","executionInfo":{"status":"aborted","timestamp":1658319905935,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Archived"],"metadata":{"id":"dpzo6gk-5TKc"}},{"cell_type":"code","source":[""],"metadata":{"id":"UlrXYw1g5YLv","executionInfo":{"status":"aborted","timestamp":1658319905935,"user_tz":-120,"elapsed":26,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Py_Easymail 20220703.ipynb","provenance":[{"file_id":"https://github.com/franckglastre/NLP-Datascientest/blob/Nicolas/Py_Easymail.ipynb","timestamp":1656881904177}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}