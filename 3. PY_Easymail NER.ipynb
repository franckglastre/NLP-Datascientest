{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. PY_Easymail NER.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM/vTLJfGAyZOesqAuGjaUg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":[""],"metadata":{"id":"dfnw6mqAKj2R","executionInfo":{"status":"ok","timestamp":1659912309646,"user_tz":-120,"elapsed":482,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"pMbyUF71KkWI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659912343728,"user_tz":-120,"elapsed":33692,"user":{"displayName":"Nico T","userId":"09615745923254077330"}},"outputId":"989cc0ba-a2e2-4652-db7b-e3cc144d2b03"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","import pandas as pd\n","df_emails = pd.read_csv\n","\n","\n","file_path = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/\"\n","file_name = \"enron_unique_1000\"\n","file = file_path+file_name+'.csv'\n","\n","df_emails = pd.read_csv(file)\n","df_emails.tail(10)\n","deb = 0\n","fin = df_emails.shape[0]\n"],"metadata":{"id":"ObURge81HNp8","executionInfo":{"status":"ok","timestamp":1659912345821,"user_tz":-120,"elapsed":2104,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# SAUVEGARDE en csv du résultat.\n","def svgd_csv_xls (file_path,file_name):\n","\n","# to .CSV\n","  file_extension = \".csv\"\n","  file = file_path+file_name+file_extension\n","  print(\"File : \",file)\n","  df_emails.to_csv(file, encoding='utf-8', index=False)\n","# df_emails[deb:fin].to_csv(file, encoding='utf-8', index=False)\n","  print(\"Svgde effectuée\")\n","  return\n"],"metadata":{"id":"fctKPt5mVRvu","executionInfo":{"status":"ok","timestamp":1659912345822,"user_tz":-120,"elapsed":13,"user":{"displayName":"Nico T","userId":"09615745923254077330"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install -U spacy\n","!python -m spacy download en_core_web_lg\n","# ligne ci-dessous a réexecuter ssi reinit du notebook\n","!pip install spacy-transformers"],"metadata":{"id":"qWFwwbMUHMTr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b416b92-7989-411d-f6cf-135b11a7de11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","2022-08-07 22:45:57.974979: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-lg==3.4.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n","\u001b[K     |███████████████████████████████▍| 576.6 MB 1.1 MB/s eta 0:00:10"]}]},{"cell_type":"code","source":["import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","stopwords=list(STOP_WORDS)\n","from string import punctuation\n","punctuation=punctuation+ '\\n'"],"metadata":{"id":"rt026BXrHNYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIO5lf_EF-VL"},"outputs":[],"source":["df_emails['NER_header'] = ''                # Spacy NER\n","df_emails['NER_body'] = ''                  # Spacy NER"]},{"cell_type":"code","source":["# A n'utiliser que pour la vectorisation et NER (?) et pas pour les résumés.\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","stopwords=list(STOP_WORDS)\n","\n","def remove_stop_words(text,stopwords):\n","  lst=[]\n","#  for token in str(text).split():\n","  for token in text.split():\n","    if token.lower() not in stopwords:    #checking whether the word is not \n","      lst.append(token)                    #present in the stopword list.      \n","      result = ' '.join(lst)\n","  return result\n","\n","def remove_stopwords(text):\n","    words = [w for w in text if w not in stopwords]\n","    return words \n","\n","# df_emails['body_clean'] = df_emails['body'].apply(lambda x : remove_stop_words(x,stopwords))"],"metadata":{"id":"PPnJuh_MHrpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://www.thepythoncode.com/article/named-entity-recognition-using-transformers-and-spacy\n","\n","import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_lg')\n","spacy_stopwords = nlp.Defaults.stop_words\n","stopwords = spacy_stopwords\n","print(\"Stopwords :\",spacy_stopwords)\n","\n","for x in range(deb,fin):\n","# subject\n","  subj = df_emails.iloc[x]['header']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_header'][x] = doc_subj.ents\n","\n","# body\n","  subj = df_emails.iloc[x]['body']\n","#  print(x,' - ',subj)\n","  doc_subj = nlp(str(subj))\n","  df_emails['NER_body'][x] = doc_subj.ents\n","\n","file_path = \"/content/drive/MyDrive/Datascientest/Projet PY_email Datascientest/Data/Enron Cleaned Data/\"\n","#file_name = \"enron_unique_output\"\n","svgd_csv_xls (file_path,file_name)"],"metadata":{"id":"hJK8ObWXHsju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","def ner_sm(text):\n","  # load the English CPU-optimized pipeline\n","  # print('Modele : en_core_web_sm')\n","  nlp = spacy.load(\"en_core_web_sm\")\n","  doc = nlp(text)\n","  # spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n","  return doc.ents\n","\n","def ner_trf(text):\n","  # load the English transformer pipeline (roberta-base) using spaCy\n","  # print('Modele : en_core_web_trf')\n","  nlp_trf = spacy.load('en_core_web_trf')\n","  # perform inference on the model\n","  doc_trf = nlp_trf(text)\n","  # display the doc with jupyter mode\n","  # spacy.displacy.render(doc_trf, style=\"ent\", jupyter=True)\n","  return doc_trf\n"],"metadata":{"id":"_YNU-3wpHN6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(deb,fin)\n","print(file_path)\n","print(file_name)\n","\n","for id in range(deb,fin):\n","  # print('ID:',id,)\n","  # subject\n","  text = str(df_emails.iloc[id]['header'])\n","  #print(id,' - header :',text)\n","  df_emails['NER_header'][id] = ner_sm(text)\n","#  print(\"df_emails['NER_header'][id] :\",df_emails['NER_header'][id])\n","\n","  # body\n","  text = str(df_emails.iloc[id]['body_clean'])\n","  #print(id,' - body :',text)\n","  df_emails['NER_body'][id] = ner_sm(text)\n","#  print(\"df_emails['NER_body'][id] :\",df_emails['NER_body'][id])\n","#  print(\"\\n\")\n","#  print(df_emails['NER_header'][id])\n","#  print(df_emails['NER_body'][id])\n","\n","  \n","  # Svgd version intermédiaire\n","  if int(id/100) == id/100:\n","    file_name_tmp = \"enron_unique_output_\"+str(id)\n","    file = file_path+file_name_tmp\n","    svgd_csv_xls (file_path,file_name_tmp)\n","    print(file_name_tmp,\" sauvegardé.\")   \n","\n"],"metadata":{"id":"RB-friBTIh7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Svgd version finale\n","file_name = file_name+\"_NER\"\n","svgd_csv_xls (file_path,file_name)\n","print(file_name,\" sauvegardé (version finale).\")"],"metadata":{"id":"0E6o8sbkIiOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"PXv-Ij6sIvyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"BRPW5qG6Iwuv"},"execution_count":null,"outputs":[]}]}